{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "\n",
    "* Computers are good at answering questions with single verifiable answers. For Example, querying “Who is the Prime Minister of India?” on google, will give a perfect answer. When it comes to answering subjective aspects of a question, Humans do a much better job than what computers do. Few subjective aspects include \n",
    "    * *Is the question understandable?*\n",
    "    * *Is the question conversational?*\n",
    "    * *Is the answer to the question understandable?*\n",
    "* The CrowdSource team at Google Research, has collected data on a number of these subjective aspects for each question-answer pair. Crowdsource gathers your feedback, and feedback from others around the world, which helps the machine to learn from accurate examples and improves the services provided by google like Maps, Translate etc. \n",
    "\n",
    "* The question-answer pairs were gathered from nearly 70 different websites. The raters received minimal guidance and training, and relied largely on their intelligence to answer subjective aspects of the prompts. As such, each prompt was simplified in such a way so that raters could simply use their common-sense to complete the task.\n",
    "\n",
    "* The task here is to build a predictive algorithm which would quantify these subjective aspects given a question-answer pair.\n",
    "* **Evaluation Metric** - The Evaluation Metric for this competition is *Spearman Rank Correlation Coefficient*. The Spearman's rank correlation is computed for each target column, and the mean of these values is calculated for the submission score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-25T13:23:31.868406Z",
     "iopub.status.busy": "2020-08-25T13:23:31.867590Z",
     "iopub.status.idle": "2020-08-25T13:23:31.902396Z",
     "shell.execute_reply": "2020-08-25T13:23:31.902923Z"
    },
    "papermill": {
     "duration": 0.052979,
     "end_time": "2020-08-25T13:23:31.903069",
     "exception": false,
     "start_time": "2020-08-25T13:23:31.850090",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/bertbaseuncasedcomplete/bert-model/vocab.txt\n",
      "/kaggle/input/bertbaseuncasedcomplete/bert-model/config.json\n",
      "/kaggle/input/bertbaseuncasedcomplete/bert-model/tokenizer_config.json\n",
      "/kaggle/input/bertbaseuncasedcomplete/bert-model/tf_model.h5\n",
      "/kaggle/input/bertbaseuncasedcomplete/bert-model/special_tokens_map.json\n",
      "/kaggle/input/bertbaseuncased/bert-base-uncased-vocab.txt\n",
      "/kaggle/input/bertbaseuncased/bert-base-uncased/bert-base-uncased/config.json\n",
      "/kaggle/input/bertbaseuncased/bert-base-uncased/bert-base-uncased/tf_model.h5\n",
      "/kaggle/input/universalsentenceencoderqa3/saved_model.pb\n",
      "/kaggle/input/universalsentenceencoderqa3/variables/variables.index\n",
      "/kaggle/input/universalsentenceencoderqa3/variables/variables.data-00000-of-00001\n",
      "/kaggle/input/fasttextwikinewssubwords300d/fasttext-wiki-news-subwords-300\n",
      "/kaggle/input/xlnetbasecased/config-xlnet-base-cased/config.json\n",
      "/kaggle/input/xlnetbasecased/model-xlnet-base-cased/config.json\n",
      "/kaggle/input/xlnetbasecased/model-xlnet-base-cased/tf_model.h5\n",
      "/kaggle/input/xlnetbasecased/tokenizer/tokenizer_config.json\n",
      "/kaggle/input/xlnetbasecased/tokenizer/special_tokens_map.json\n",
      "/kaggle/input/xlnetbasecased/tokenizer/spiece.model\n",
      "/kaggle/input/model1/model-1.hdf5\n",
      "/kaggle/input/model-1-quest/kaggle/working/models/vocab.txt\n",
      "/kaggle/input/model-1-quest/kaggle/working/models/config.json\n",
      "/kaggle/input/model-1-quest/kaggle/working/models/tokenizer_config.json\n",
      "/kaggle/input/model-1-quest/kaggle/working/models/tf_model.h5\n",
      "/kaggle/input/model-1-quest/kaggle/working/models/special_tokens_map.json\n",
      "/kaggle/input/google-quest-challenge/test.csv\n",
      "/kaggle/input/google-quest-challenge/sample_submission.csv\n",
      "/kaggle/input/google-quest-challenge/train.csv\n",
      "/kaggle/input/universal-sentence-encoder/saved_model.pb\n",
      "/kaggle/input/universal-sentence-encoder/variables/variables.index\n",
      "/kaggle/input/universal-sentence-encoder/variables/variables.data-00000-of-00001\n",
      "/kaggle/input/distil-bert-model/model_distil/vocab.txt\n",
      "/kaggle/input/distil-bert-model/model_distil/config.json\n",
      "/kaggle/input/distil-bert-model/model_distil/tokenizer_config.json\n",
      "/kaggle/input/distil-bert-model/model_distil/tf_model.h5\n",
      "/kaggle/input/distil-bert-model/model_distil/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-25T13:23:31.932405Z",
     "iopub.status.busy": "2020-08-25T13:23:31.931665Z",
     "iopub.status.idle": "2020-08-25T13:23:40.897585Z",
     "shell.execute_reply": "2020-08-25T13:23:40.896472Z"
    },
    "papermill": {
     "duration": 8.983,
     "end_time": "2020-08-25T13:23:40.897718",
     "exception": false,
     "start_time": "2020-08-25T13:23:31.914718",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import transformers\n",
    "import tensorflow as tf\n",
    "from scipy.stats import spearmanr\n",
    "import tensorflow_hub as hub\n",
    "import re\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import gc\n",
    "from sklearn.model_selection import GroupKFold,KFold\n",
    "from scipy.stats import spearmanr, rankdata\n",
    "from sklearn.linear_model import MultiTaskElasticNet\n",
    "import string\n",
    "from collections import Counter\n",
    "from gensim.models import Word2Vec\n",
    "from transformers import XLNetConfig, TFXLNetModel, XLNetTokenizer, TFXLNetMainLayer, BertConfig, TFBertMainLayer, BertTokenizer, TFBertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-25T13:23:40.929366Z",
     "iopub.status.busy": "2020-08-25T13:23:40.928516Z",
     "iopub.status.idle": "2020-08-25T13:23:40.931336Z",
     "shell.execute_reply": "2020-08-25T13:23:40.930843Z"
    },
    "papermill": {
     "duration": 0.022507,
     "end_time": "2020-08-25T13:23:40.931435",
     "exception": false,
     "start_time": "2020-08-25T13:23:40.908928",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DIR = '/kaggle/input/google-quest-challenge'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-25T13:23:40.957315Z",
     "iopub.status.busy": "2020-08-25T13:23:40.956728Z",
     "iopub.status.idle": "2020-08-25T13:23:41.099625Z",
     "shell.execute_reply": "2020-08-25T13:23:41.099075Z"
    },
    "papermill": {
     "duration": 0.157404,
     "end_time": "2020-08-25T13:23:41.099729",
     "exception": false,
     "start_time": "2020-08-25T13:23:40.942325",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "xlnet_tokenizer = XLNetTokenizer.from_pretrained('/kaggle/input/xlnetbasecased/tokenizer')\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('/kaggle/input/bertbaseuncasedcomplete/bert-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-25T13:23:41.127915Z",
     "iopub.status.busy": "2020-08-25T13:23:41.127313Z",
     "iopub.status.idle": "2020-08-25T13:23:41.320114Z",
     "shell.execute_reply": "2020-08-25T13:23:41.321058Z"
    },
    "papermill": {
     "duration": 0.210273,
     "end_time": "2020-08-25T13:23:41.321239",
     "exception": false,
     "start_time": "2020-08-25T13:23:41.110966",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(DIR+'/train.csv')\n",
    "test_df = pd.read_csv(DIR+'/test.csv')\n",
    "cols = train_df.columns[11:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-25T13:23:41.373140Z",
     "iopub.status.busy": "2020-08-25T13:23:41.357596Z",
     "iopub.status.idle": "2020-08-25T13:28:58.486806Z",
     "shell.execute_reply": "2020-08-25T13:28:58.485563Z"
    },
    "papermill": {
     "duration": 317.153892,
     "end_time": "2020-08-25T13:28:58.486951",
     "exception": false,
     "start_time": "2020-08-25T13:23:41.333059",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize_input(tokenizer, s1, s2, tags, data_name, max_length, tokenizer_name = 'bert'):\n",
    "if s2 is not None:\n",
    "    x = tokenizer.encode_plus(s1, s2, pad_to_max_length=False)\n",
    "    if len(x['input_ids']) > max_length:\n",
    "        segment_1 = int(0.25*max_length)\n",
    "        x['input_ids'] = x['input_ids'][:segment_1] + x['input_ids'][-(max_length-segment_1):]\n",
    "        x['attention_mask'] = x['attention_mask'][:segment_1] + x['attention_mask'][-(max_length-segment_1):]\n",
    "        x['token_type_ids'] = x['token_type_ids'][:segment_1] + x['token_type_ids'][-(max_length-segment_1):]\n",
    "    else:\n",
    "        diff = max_length - len(x['input_ids'])\n",
    "        if tokenizer_name == 'xlnet':\n",
    "            x['input_ids'] = [tokenizer.pad_token_id]*diff + x['input_ids']\n",
    "            x['attention_mask'] = [0]*diff + x['attention_mask']\n",
    "            x['token_type_ids'] = [tokenizer.pad_token_type_id]*diff + x['token_type_ids']\n",
    "        else:\n",
    "            x['input_ids'] = x['input_ids'] + [tokenizer.pad_token_id]*diff\n",
    "            x['attention_mask'] = x['attention_mask'] + [0]*diff\n",
    "            x['token_type_ids'] = x['token_type_ids'] + [0]*diff\n",
    "      \n",
    "    else:\n",
    "        x = tokenizer.encode_plus(s1)\n",
    "        if len(x['input_ids']) > max_length:\n",
    "            segment_1 = int(0.25*max_length)\n",
    "            x['input_ids'] = x['input_ids'][:segment_1] + x['input_ids'][-(max_length-segment_1):]\n",
    "            x['attention_mask'] = x['attention_mask'][:segment_1] + x['attention_mask'][-(max_length-segment_1):]\n",
    "            x['token_type_ids'] = x['token_type_ids'][:segment_1] + x['token_type_ids'][-(max_length-segment_1):]\n",
    "        else:\n",
    "            diff = max_length - len(x['input_ids'])\n",
    "            if tokenizer_name == 'xlnet':\n",
    "                x['input_ids'] = [tokenizer.pad_token_id]*diff + x['input_ids']\n",
    "                x['attention_mask'] = [0]*diff + x['attention_mask']\n",
    "                x['token_type_ids'] = [tokenizer.pad_token_type_id]*diff + x['token_type_ids']\n",
    "            else:\n",
    "                x['input_ids'] = x['input_ids'] + [tokenizer.pad_token_id]*diff\n",
    "                x['attention_mask'] = x['attention_mask'] + [0]*diff\n",
    "                x['token_type_ids'] = x['token_type_ids'] + [tokenizer.pad_token_type_id]*diff\n",
    "  \n",
    "    data[data_name][tags[0]].append(x['input_ids']) \n",
    "    data[data_name][tags[1]].append(x['token_type_ids'])\n",
    "    data[data_name][tags[2]].append(x['attention_mask']) \n",
    "\n",
    "data = {}\n",
    "# ******************************************XLNET*************************************************************************************\n",
    "data['xlnet_train_t_a'] = {}\n",
    "data['xlnet_train_q_a'] = {}\n",
    "data['xlnet_train_t_q'] = {}\n",
    "data['xlnet_train_q'] = {}\n",
    "data['xlnet_train_a'] = {}\n",
    "\n",
    "data['xlnet_test_t_a'] = {}\n",
    "data['xlnet_test_q_a'] = {}\n",
    "data['xlnet_test_t_q'] = {}\n",
    "data['xlnet_test_q'] = {}\n",
    "data['xlnet_test_a'] = {}\n",
    "\n",
    "tags = ['input_ids', 'token_type_ids', 'attention_masks']\n",
    "data['xlnet_train_t_a'][tags[0]], data['xlnet_train_t_a'][tags[1]], data['xlnet_train_t_a'][tags[2]] = [], [], []\n",
    "data['xlnet_train_q_a'][tags[0]], data['xlnet_train_q_a'][tags[1]], data['xlnet_train_q_a'][tags[2]] = [], [], []\n",
    "data['xlnet_train_t_q'][tags[0]], data['xlnet_train_t_q'][tags[1]], data['xlnet_train_t_q'][tags[2]] = [], [], []\n",
    "data['xlnet_train_q'][tags[0]], data['xlnet_train_q'][tags[1]], data['xlnet_train_q'][tags[2]] = [], [], []\n",
    "data['xlnet_train_a'][tags[0]], data['xlnet_train_a'][tags[1]], data['xlnet_train_a'][tags[2]] = [], [], []\n",
    "\n",
    "\n",
    "data['xlnet_test_t_a'][tags[0]], data['xlnet_test_t_a'][tags[1]], data['xlnet_test_t_a'][tags[2]] = [], [], []\n",
    "data['xlnet_test_q_a'][tags[0]], data['xlnet_test_q_a'][tags[1]], data['xlnet_test_q_a'][tags[2]] = [], [], []\n",
    "data['xlnet_test_t_q'][tags[0]], data['xlnet_test_t_q'][tags[1]], data['xlnet_test_t_q'][tags[2]] = [], [], []\n",
    "data['xlnet_test_q'][tags[0]], data['xlnet_test_q'][tags[1]], data['xlnet_test_q'][tags[2]] = [], [], []\n",
    "data['xlnet_test_a'][tags[0]], data['xlnet_test_a'][tags[1]], data['xlnet_test_a'][tags[2]] = [], [], []\n",
    "\n",
    "\n",
    "for i in range(train_df.shape[0]):\n",
    "    tokenize_input(xlnet_tokenizer, train_df.loc[i, 'question_title'], train_df.loc[i, 'answer'], tags, \n",
    "                   'xlnet_train_t_a', 512, 'xlnet')\n",
    "    tokenize_input(xlnet_tokenizer, train_df.loc[i, 'question_body'], train_df.loc[i, 'answer'], tags, \n",
    "                   'xlnet_train_q_a', 512, 'xlnet')\n",
    "    tokenize_input(xlnet_tokenizer, train_df.loc[i, 'question_title'], train_df.loc[i, 'question_body'], tags, \n",
    "                   'xlnet_train_t_q', 512, 'xlnet')\n",
    "    tokenize_input(xlnet_tokenizer, train_df.loc[i, 'question_body'], None, tags, 'xlnet_train_q', 512, 'xlnet')\n",
    "    tokenize_input(xlnet_tokenizer, train_df.loc[i, 'answer'], None, tags, 'xlnet_train_a', 512, 'xlnet')\n",
    "for i in range(test_df.shape[0]):\n",
    "    tokenize_input(xlnet_tokenizer, test_df.loc[i, 'question_title'], test_df.loc[i, 'answer'], tags, \n",
    "                   'xlnet_test_t_a', 512, 'xlnet')\n",
    "    tokenize_input(xlnet_tokenizer, test_df.loc[i, 'question_body'], test_df.loc[i, 'answer'], tags, \n",
    "                   'xlnet_test_q_a', 512, 'xlnet')\n",
    "    tokenize_input(xlnet_tokenizer, test_df.loc[i, 'question_title'], test_df.loc[i, 'question_body'], tags, \n",
    "                   'xlnet_test_t_q', 512, 'xlnet')\n",
    "    tokenize_input(xlnet_tokenizer, test_df.loc[i, 'question_body'], None, tags, 'xlnet_test_q', 512, 'xlnet')\n",
    "    tokenize_input(xlnet_tokenizer, test_df.loc[i, 'answer'], None, tags, 'xlnet_test_a', 512, 'xlnet')\n",
    "\n",
    "# ******************************************BERT*************************************************************************************\n",
    "\n",
    "data['bert_train_t_a'] = {}\n",
    "data['bert_train_q_a'] = {}\n",
    "data['bert_train_t_q'] = {}\n",
    "data['bert_train_q'] = {}\n",
    "data['bert_train_a'] = {}\n",
    "\n",
    "data['bert_test_t_a'] = {}\n",
    "data['bert_test_q_a'] = {}\n",
    "data['bert_test_t_q'] = {}\n",
    "data['bert_test_q'] = {}\n",
    "data['bert_test_a'] = {}\n",
    "\n",
    "data['bert_train_t_a'][tags[0]], data['bert_train_t_a'][tags[1]], data['bert_train_t_a'][tags[2]] = [], [], []\n",
    "data['bert_train_q_a'][tags[0]], data['bert_train_q_a'][tags[1]], data['bert_train_q_a'][tags[2]] = [], [], []\n",
    "data['bert_train_t_q'][tags[0]], data['bert_train_t_q'][tags[1]], data['bert_train_t_q'][tags[2]] = [], [], []\n",
    "data['bert_train_q'][tags[0]], data['bert_train_q'][tags[1]], data['bert_train_q'][tags[2]] = [], [], []\n",
    "data['bert_train_a'][tags[0]], data['bert_train_a'][tags[1]], data['bert_train_a'][tags[2]] = [], [], []\n",
    "\n",
    "data['bert_test_t_a'][tags[0]], data['bert_test_t_a'][tags[1]], data['bert_test_t_a'][tags[2]] = [], [], []\n",
    "data['bert_test_q_a'][tags[0]], data['bert_test_q_a'][tags[1]], data['bert_test_q_a'][tags[2]] = [], [], []\n",
    "data['bert_test_t_q'][tags[0]], data['bert_test_t_q'][tags[1]], data['bert_test_t_q'][tags[2]] = [], [], []\n",
    "data['bert_test_q'][tags[0]], data['bert_test_q'][tags[1]], data['bert_test_q'][tags[2]] = [], [], []\n",
    "data['bert_test_a'][tags[0]], data['bert_test_a'][tags[1]], data['bert_test_a'][tags[2]] = [], [], []\n",
    "\n",
    "for i in range(train_df.shape[0]):\n",
    "    tokenize_input(bert_tokenizer, train_df.loc[i, 'question_title'], train_df.loc[i, 'answer'], tags, \n",
    "                   'bert_train_t_a', 512, 'bert')\n",
    "    tokenize_input(bert_tokenizer, train_df.loc[i, 'question_body'], train_df.loc[i, 'answer'], tags, \n",
    "                   'bert_train_q_a', 512, 'bert')\n",
    "    tokenize_input(bert_tokenizer, train_df.loc[i, 'question_title'], train_df.loc[i, 'question_body'], tags, \n",
    "                   'bert_train_t_q', 512, 'bert')\n",
    "    tokenize_input(bert_tokenizer, train_df.loc[i, 'question_body'], None, tags, 'bert_train_q', 512, 'bert')\n",
    "    tokenize_input(bert_tokenizer, train_df.loc[i, 'answer'], None, tags, 'bert_train_a', 512, 'bert')\n",
    "for i in range(test_df.shape[0]):\n",
    "    tokenize_input(bert_tokenizer, test_df.loc[i, 'question_title'], test_df.loc[i, 'answer'], tags, \n",
    "                   'bert_test_t_a', 512, 'bert')\n",
    "    tokenize_input(bert_tokenizer, test_df.loc[i, 'question_body'], test_df.loc[i, 'answer'], tags, \n",
    "                   'bert_test_q_a', 512, 'bert')\n",
    "    tokenize_input(bert_tokenizer, test_df.loc[i, 'question_title'], test_df.loc[i, 'question_body'], tags, \n",
    "                   'bert_test_t_q', 512, 'bert')\n",
    "    tokenize_input(bert_tokenizer, test_df.loc[i, 'question_body'], None, tags, 'bert_test_q', 512, 'bert')\n",
    "    tokenize_input(bert_tokenizer, test_df.loc[i, 'answer'], None, tags, 'bert_test_a', 512, 'bert')\n",
    "\n",
    "for key, _ in data.items():\n",
    "    for k, _ in data[key].items():\n",
    "        data[key][k] = np.array(data[key][k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-25T13:28:58.522902Z",
     "iopub.status.busy": "2020-08-25T13:28:58.521176Z",
     "iopub.status.idle": "2020-08-25T13:28:58.523676Z",
     "shell.execute_reply": "2020-08-25T13:28:58.524156Z"
    },
    "papermill": {
     "duration": 0.024597,
     "end_time": "2020-08-25T13:28:58.524297",
     "exception": false,
     "start_time": "2020-08-25T13:28:58.499700",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def SpearmanCorrCoeff(A, B):\n",
    "    overall_score = 0\n",
    "    for index in range(A.shape[1]):\n",
    "        overall_score += spearmanr(A[:, index], B[:, index]).correlation\n",
    "    return overall_score/30\n",
    "class PredictCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "    def on_epoch_end(self, epoch, logs = {}):\n",
    "        predictions = self.model.predict(self.data)\n",
    "        print('\\n\\t Validation Score - ' + str(SpearmanCorrCoeff(self.labels, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-25T13:28:58.557292Z",
     "iopub.status.busy": "2020-08-25T13:28:58.556475Z",
     "iopub.status.idle": "2020-08-25T13:28:58.569105Z",
     "shell.execute_reply": "2020-08-25T13:28:58.568599Z"
    },
    "papermill": {
     "duration": 0.032898,
     "end_time": "2020-08-25T13:28:58.569228",
     "exception": false,
     "start_time": "2020-08-25T13:28:58.536330",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BERT(TFBertModel):\n",
    "    def __init__(self, config, *inputs, **kwrgs):\n",
    "        super(BERT, self).__init__(config, *inputs, **kwrgs)\n",
    "        self.bert = TFBertMainLayer(config, name = 'bert')\n",
    "        for i in range(1, 45):\n",
    "            self.bert.submodules[-i].trainable = False\n",
    "      \n",
    "    def call(self, inputs, **kwrgs):\n",
    "        outputs = self.bert(inputs)\n",
    "        hidden_states = outputs[2]\n",
    "        h12 = hidden_states[-1][:, 0, :]\n",
    "        h11 = hidden_states[-2][:, 0, :]\n",
    "        h10 = hidden_states[-3][:, 0, :]\n",
    "        h9 = hidden_states[-4][:, 0, :]\n",
    "        concat = tf.keras.layers.Concatenate(axis = -1)([h9, h10, h11, h12])\n",
    "        return concat\n",
    "\n",
    "class XLNet(TFXLNetModel):\n",
    "    def __init__(self, config, *inputs, **kwrgs):\n",
    "        super(XLNet, self).__init__(config, *inputs, **kwrgs)\n",
    "        self.transformer = TFXLNetMainLayer(config, name = 'transformer')\n",
    "        for i in range(1, 3):\n",
    "            self.transformer.layer[-i].trainable = False\n",
    "    def call(self, inputs, **kwrgs):\n",
    "        outputs = self.transformer(inputs)\n",
    "        hidden_states = outputs[1]\n",
    "        h12 = hidden_states[-1][:, 0, :]\n",
    "        h11 = hidden_states[-2][:, 0, :]\n",
    "        h10 = hidden_states[-3][:, 0, :]\n",
    "        h9 = hidden_states[-4][:, 0, :]\n",
    "        concat = tf.keras.layers.Concatenate(axis = -1)([h9, h10, h11, h12])\n",
    "        return concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-25T13:28:58.608352Z",
     "iopub.status.busy": "2020-08-25T13:28:58.601991Z",
     "iopub.status.idle": "2020-08-25T13:28:58.611386Z",
     "shell.execute_reply": "2020-08-25T13:28:58.610884Z"
    },
    "papermill": {
     "duration": 0.029833,
     "end_time": "2020-08-25T13:28:58.611485",
     "exception": false,
     "start_time": "2020-08-25T13:28:58.581652",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_model(name):\n",
    "    id_1 = tf.keras.Input(shape = (512), dtype = tf.int32)\n",
    "    id_2 = tf.keras.Input(shape = (512), dtype = tf.int32)\n",
    "\n",
    "    type_id_1 = tf.keras.Input(shape = (512), dtype = tf.int32)\n",
    "    type_id_2 = tf.keras.Input(shape = (512), dtype = tf.int32)\n",
    "\n",
    "    a1 = tf.keras.Input(shape = (512), dtype = tf.int32)\n",
    "    a2 = tf.keras.Input(shape = (512), dtype = tf.int32)\n",
    "    if name == 'xlnet':\n",
    "        config = XLNetConfig.from_pretrained('/kaggle/input/xlnetbasecased/config-xlnet-base-cased', \n",
    "                                             output_hidden_states = True)\n",
    "        transformer = XLNet.from_pretrained('/kaggle/input/xlnetbasecased/model-xlnet-base-cased', \n",
    "                                            config = config)\n",
    "                                                \n",
    "    else:\n",
    "        config = BertConfig.from_pretrained('/kaggle/input/bertbaseuncasedcomplete/bert-model', \n",
    "                                            output_hidden_states = True)\n",
    "        transformer = BERT.from_pretrained('/kaggle/input/bertbaseuncasedcomplete/bert-model', \n",
    "                                           config = config)\n",
    "  \n",
    "    out_1 = transformer({'input_ids':id_1, 'attention_mask':a1, 'token_type_ids':type_id_1})\n",
    "    out_2 = transformer({'input_ids':id_2, 'attention_mask':a2, 'token_type_ids':type_id_2})\n",
    "  \n",
    "    concat = tf.keras.layers.Concatenate(axis = -1)([out_1, out_2])\n",
    "    dense = tf.keras.layers.Dense(30, activation = 'sigmoid')(concat)\n",
    "    return tf.keras.Model(inputs = [id_1, id_2, type_id_1, type_id_2, a1, a2], outputs = [dense])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-25T13:28:58.670646Z",
     "iopub.status.busy": "2020-08-25T13:28:58.649636Z",
     "iopub.status.idle": "2020-08-25T14:40:47.792398Z",
     "shell.execute_reply": "2020-08-25T14:40:47.791845Z"
    },
    "papermill": {
     "duration": 4309.168498,
     "end_time": "2020-08-25T14:40:47.792526",
     "exception": false,
     "start_time": "2020-08-25T13:28:58.624028",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4863 samples\n",
      "Epoch 1/2\n",
      "4860/4863 [============================>.] - ETA: 0s - loss: 0.4143Epoch 2/2\n",
      "4859/4863 [============================>.] - ETA: 1s - loss: 0.3736\n",
      "####################################################################################################################\n",
      "\n",
      "Train on 4863 samples\n",
      "Epoch 1/2\n",
      "4860/4863 [============================>.] - ETA: 0s - loss: 0.3911Epoch 2/2\n",
      "4859/4863 [============================>.] - ETA: 0s - loss: 0.3619"
     ]
    }
   ],
   "source": [
    "gkf = GroupKFold(n_splits = 5).split(X = train_df.url, groups = train_df.url)\n",
    "for fold, (train_idx, valid_idx) in enumerate(gkf):\n",
    "    if fold != 0:\n",
    "        continue\n",
    "    final_outputs = train_df[cols].values.astype(np.float16)\n",
    "    tf.keras.backend.clear_session()\n",
    "    xlnet_train_inputs = (\n",
    "                    data['xlnet_train_a'][tags[0]][train_idx], data['xlnet_train_t_q'][tags[0]][train_idx], \n",
    "        data['xlnet_train_a'][tags[1]][train_idx], data['xlnet_train_t_q'][tags[1]][train_idx],\n",
    "                   data['xlnet_train_a'][tags[2]][train_idx], data['xlnet_train_t_q'][tags[2]][train_idx]  \n",
    "\n",
    "                 )\n",
    "    xlnet_valid_inputs = (\n",
    "                    data['xlnet_train_a'][tags[0]][valid_idx], data['xlnet_train_t_q'][tags[0]][valid_idx], \n",
    "        data['xlnet_train_a'][tags[1]][valid_idx], data['xlnet_train_t_q'][tags[1]][valid_idx],\n",
    "                   data['xlnet_train_a'][tags[2]][valid_idx], data['xlnet_train_t_q'][tags[2]][valid_idx]  \n",
    "\n",
    "                  )\n",
    "    bert_train_inputs = (\n",
    "                    data['bert_train_a'][tags[0]][train_idx], data['bert_train_t_q'][tags[0]][train_idx], \n",
    "        data['bert_train_a'][tags[1]][train_idx], data['bert_train_t_q'][tags[1]][train_idx],\n",
    "                   data['bert_train_a'][tags[2]][train_idx], data['bert_train_t_q'][tags[2]][train_idx]  \n",
    "\n",
    "                 )\n",
    "    bert_valid_inputs = (\n",
    "                    data['bert_train_a'][tags[0]][valid_idx], data['bert_train_t_q'][tags[0]][valid_idx], \n",
    "        data['bert_train_a'][tags[1]][valid_idx], data['bert_train_t_q'][tags[1]][valid_idx],\n",
    "                   data['bert_train_a'][tags[2]][valid_idx], data['bert_train_t_q'][tags[2]][valid_idx]  \n",
    "\n",
    "                  )\n",
    "\n",
    "\n",
    "    xlnet_model = create_model('xlnet')\n",
    "    xlnet_model.compile(tf.keras.optimizers.Adam(learning_rate = 2.3*1e-5), \n",
    "                        loss = tf.keras.losses.BinaryCrossentropy())\n",
    "    xlnet_model.fit(x = xlnet_train_inputs, y = final_outputs[train_idx], epochs = 2, batch_size = 4, \n",
    "                    steps_per_epoch = train_idx.shape[0]//4)\n",
    "    tf.keras.backend.clear_session()\n",
    "    print(\"################################################################################\\n\")\n",
    "    bert_model = create_model('bert')\n",
    "    bert_model.compile(tf.keras.optimizers.Adam(learning_rate = 2.3*1e-5), \n",
    "                       loss = tf.keras.losses.BinaryCrossentropy())\n",
    "    bert_model.fit(x = bert_train_inputs, y = final_outputs[train_idx], epochs = 2, batch_size = 4, \n",
    "                   steps_per_epoch = train_idx.shape[0]//4)\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-25T14:40:51.190527Z",
     "iopub.status.busy": "2020-08-25T14:40:51.179715Z",
     "iopub.status.idle": "2020-08-25T14:40:51.193679Z",
     "shell.execute_reply": "2020-08-25T14:40:51.192972Z"
    },
    "papermill": {
     "duration": 1.772569,
     "end_time": "2020-08-25T14:40:51.193794",
     "exception": false,
     "start_time": "2020-08-25T14:40:49.421225",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Optimize:\n",
    "    def __init__(self):\n",
    "        self.clips = [[0, 1] for i in range(30)]\n",
    "        self.ab_ = [(0, 0.15), (0.85, 1)]\n",
    "        self.new_scores, self.scores = (None, None)\n",
    "    def fit(self, labels, preds):\n",
    "        self.scores = [SpearmanCorrCoeff(labels[:, i:i+1], preds[:, i:i+1]) for i in range(30)]\n",
    "        for i in range(30):\n",
    "            self.golden_section_search(labels[:, i:i+1], preds[:, i:i+1], i, 0)\n",
    "            self.golden_section_search(labels[:, i:i+1], preds[:, i:i+1], i, 1)\n",
    "        self.new_scores = [np.nan_to_num(SpearmanCorrCoeff(labels[:, i:i+1], \n",
    "            np.clip(preds[:, i:i+1], self.clips[i][0], self.clips[i][1]))) for i in range(30)]\n",
    "        for i in range(30):\n",
    "            if self.scores[i] >= self.new_scores[i]:\n",
    "                self.clips[i] = [0, 1]\n",
    "    def golden_section_search(self, labels, preds, i, idx):\n",
    "        (a, b) = self.ab_[idx]\n",
    "        c = 0.618\n",
    "        x1 = b - c*(b-a)\n",
    "        x2 = (b-a)*c + a\n",
    "        \n",
    "        for epochs in range(10):\n",
    "            self.clips[i][idx] = x1\n",
    "            score_a = -self.score(labels, preds, i)\n",
    "            self.clips[i][idx] = x2\n",
    "            score_b = -self.score(labels, preds, i)\n",
    "            if np.isnan(score_a):\n",
    "                continue\n",
    "            elif np.isnan(score_b):\n",
    "                continue\n",
    "            elif score_a <= score_b:\n",
    "                b = x2\n",
    "                x2 = x1\n",
    "                x1 = b - c*(b-a)\n",
    "            else:\n",
    "                a = x1\n",
    "                x1 = x2\n",
    "                x2 = (b-a)*c + a\n",
    "        \n",
    "        self.clips[i][idx] = x1\n",
    "        score_x1 = self.score(labels, preds, i)\n",
    "        self.clips[i][idx] = x2\n",
    "        score_x2 = self.score(labels, preds, i)\n",
    "        if score_x1 > score_x2:\n",
    "            self.clips[i][idx] = x1\n",
    "        else:\n",
    "            self.clips[i][idx] = x2\n",
    "                    \n",
    "            \n",
    "    def score(self, labels, preds, i):\n",
    "        return SpearmanCorrCoeff(labels, np.clip(preds, self.clips[i][0], self.clips[i][1]))\n",
    "    def transform(self, preds):\n",
    "        temp = preds.copy()\n",
    "        for i in range(30):\n",
    "            clipped = np.clip(preds[:, i], self.clips[i][0], self.clips[i][1])\n",
    "            if np.unique(clipped).shape[0] > 1:\n",
    "                temp[:, i][:] = clipped\n",
    "        return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-25T14:40:54.657650Z",
     "iopub.status.busy": "2020-08-25T14:40:54.594670Z",
     "iopub.status.idle": "2020-08-25T14:54:48.167967Z",
     "shell.execute_reply": "2020-08-25T14:54:48.167248Z"
    },
    "papermill": {
     "duration": 835.302006,
     "end_time": "2020-08-25T14:54:48.168136",
     "exception": false,
     "start_time": "2020-08-25T14:40:52.866130",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/numpy/lib/function_base.py:2534: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/opt/conda/lib/python3.7/site-packages/numpy/lib/function_base.py:2535: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n",
      "/opt/conda/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:903: RuntimeWarning: invalid value encountered in greater\n",
      "  return (a < x) & (x < b)\n",
      "/opt/conda/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:903: RuntimeWarning: invalid value encountered in less\n",
      "  return (a < x) & (x < b)\n",
      "/opt/conda/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:1912: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= _a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Score (Before) 0.4035256392684768\n",
      "Validation Score (After) 0.416809994511061\n"
     ]
    }
   ],
   "source": [
    "xlnet_inputs = (\n",
    "                    data['xlnet_train_a'][tags[0]], data['xlnet_train_t_q'][tags[0]], \n",
    "    data['xlnet_train_a'][tags[1]], data['xlnet_train_t_q'][tags[1]],\n",
    "                   data['xlnet_train_a'][tags[2]], data['xlnet_train_t_q'][tags[2]]  \n",
    "                  \n",
    "                 )\n",
    "\n",
    "bert_inputs = (\n",
    "                    data['bert_train_a'][tags[0]], data['bert_train_t_q'][tags[0]], \n",
    "    data['bert_train_a'][tags[1]], data['bert_train_t_q'][tags[1]],\n",
    "                   data['bert_train_a'][tags[2]], data['bert_train_t_q'][tags[2]]  \n",
    "                  \n",
    "                 )\n",
    "xlnet_predictions = (xlnet_model.predict(xlnet_inputs))\n",
    "bert_predictions = (bert_model.predict(bert_inputs))\n",
    "mean_predictions = (0.5*xlnet_predictions + 0.5*bert_predictions)\n",
    "train_y = final_outputs[train_idx]\n",
    "valid_y = final_outputs[valid_idx]\n",
    "mean_train_preds = mean_predictions[train_idx]\n",
    "mean_valid_preds = mean_predictions[valid_idx]\n",
    "\n",
    "opt = Optimize()\n",
    "opt.fit(train_y, mean_train_preds)\n",
    "post_valid_preds = opt.transform(mean_valid_preds)\n",
    "print(f\"Validation Score (Before) {SpearmanCorrCoeff(valid_y, mean_valid_preds)}\")\n",
    "print(f\"Validation Score (After) {SpearmanCorrCoeff(valid_y, post_valid_preds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-25T14:54:51.525576Z",
     "iopub.status.busy": "2020-08-25T14:54:51.524677Z",
     "iopub.status.idle": "2020-08-25T14:55:57.591990Z",
     "shell.execute_reply": "2020-08-25T14:55:57.592489Z"
    },
    "papermill": {
     "duration": 67.767524,
     "end_time": "2020-08-25T14:55:57.592644",
     "exception": false,
     "start_time": "2020-08-25T14:54:49.825120",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qa_id</th>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <th>question_body_critical</th>\n",
       "      <th>question_conversational</th>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <th>question_multi_intent</th>\n",
       "      <th>...</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>0.945288</td>\n",
       "      <td>0.672799</td>\n",
       "      <td>0.338741</td>\n",
       "      <td>0.396063</td>\n",
       "      <td>0.581378</td>\n",
       "      <td>0.448282</td>\n",
       "      <td>0.695343</td>\n",
       "      <td>0.743659</td>\n",
       "      <td>0.530865</td>\n",
       "      <td>...</td>\n",
       "      <td>0.919896</td>\n",
       "      <td>0.897294</td>\n",
       "      <td>0.406054</td>\n",
       "      <td>0.957358</td>\n",
       "      <td>0.956077</td>\n",
       "      <td>0.736326</td>\n",
       "      <td>0.091482</td>\n",
       "      <td>0.027052</td>\n",
       "      <td>0.857635</td>\n",
       "      <td>0.946178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>0.882821</td>\n",
       "      <td>0.414841</td>\n",
       "      <td>0.148314</td>\n",
       "      <td>0.631014</td>\n",
       "      <td>0.787929</td>\n",
       "      <td>0.850671</td>\n",
       "      <td>0.509879</td>\n",
       "      <td>0.489665</td>\n",
       "      <td>0.139953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.725094</td>\n",
       "      <td>0.954958</td>\n",
       "      <td>0.624564</td>\n",
       "      <td>0.976141</td>\n",
       "      <td>0.964589</td>\n",
       "      <td>0.870414</td>\n",
       "      <td>0.901102</td>\n",
       "      <td>0.173739</td>\n",
       "      <td>0.155895</td>\n",
       "      <td>0.883272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>0.925923</td>\n",
       "      <td>0.579584</td>\n",
       "      <td>0.148314</td>\n",
       "      <td>0.672972</td>\n",
       "      <td>0.878834</td>\n",
       "      <td>0.858648</td>\n",
       "      <td>0.618461</td>\n",
       "      <td>0.561834</td>\n",
       "      <td>0.263809</td>\n",
       "      <td>...</td>\n",
       "      <td>0.866208</td>\n",
       "      <td>0.919860</td>\n",
       "      <td>0.557448</td>\n",
       "      <td>0.976141</td>\n",
       "      <td>0.964589</td>\n",
       "      <td>0.803503</td>\n",
       "      <td>0.091482</td>\n",
       "      <td>0.043473</td>\n",
       "      <td>0.863898</td>\n",
       "      <td>0.929245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132</td>\n",
       "      <td>0.865351</td>\n",
       "      <td>0.321677</td>\n",
       "      <td>0.148314</td>\n",
       "      <td>0.641319</td>\n",
       "      <td>0.719370</td>\n",
       "      <td>0.858648</td>\n",
       "      <td>0.559521</td>\n",
       "      <td>0.358044</td>\n",
       "      <td>0.139953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.669263</td>\n",
       "      <td>0.944348</td>\n",
       "      <td>0.656321</td>\n",
       "      <td>0.976141</td>\n",
       "      <td>0.964589</td>\n",
       "      <td>0.890407</td>\n",
       "      <td>0.790419</td>\n",
       "      <td>0.199159</td>\n",
       "      <td>0.649088</td>\n",
       "      <td>0.901653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>0.922602</td>\n",
       "      <td>0.473999</td>\n",
       "      <td>0.148314</td>\n",
       "      <td>0.766476</td>\n",
       "      <td>0.793914</td>\n",
       "      <td>0.854842</td>\n",
       "      <td>0.598358</td>\n",
       "      <td>0.612410</td>\n",
       "      <td>0.254969</td>\n",
       "      <td>...</td>\n",
       "      <td>0.788498</td>\n",
       "      <td>0.916623</td>\n",
       "      <td>0.641902</td>\n",
       "      <td>0.972269</td>\n",
       "      <td>0.962273</td>\n",
       "      <td>0.841106</td>\n",
       "      <td>0.153972</td>\n",
       "      <td>0.076906</td>\n",
       "      <td>0.699780</td>\n",
       "      <td>0.914850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   qa_id  question_asker_intent_understanding  question_body_critical  \\\n",
       "0     39                             0.945288                0.672799   \n",
       "1     46                             0.882821                0.414841   \n",
       "2     70                             0.925923                0.579584   \n",
       "3    132                             0.865351                0.321677   \n",
       "4    200                             0.922602                0.473999   \n",
       "\n",
       "   question_conversational  question_expect_short_answer  \\\n",
       "0                 0.338741                      0.396063   \n",
       "1                 0.148314                      0.631014   \n",
       "2                 0.148314                      0.672972   \n",
       "3                 0.148314                      0.641319   \n",
       "4                 0.148314                      0.766476   \n",
       "\n",
       "   question_fact_seeking  question_has_commonly_accepted_answer  \\\n",
       "0               0.581378                               0.448282   \n",
       "1               0.787929                               0.850671   \n",
       "2               0.878834                               0.858648   \n",
       "3               0.719370                               0.858648   \n",
       "4               0.793914                               0.854842   \n",
       "\n",
       "   question_interestingness_others  question_interestingness_self  \\\n",
       "0                         0.695343                       0.743659   \n",
       "1                         0.509879                       0.489665   \n",
       "2                         0.618461                       0.561834   \n",
       "3                         0.559521                       0.358044   \n",
       "4                         0.598358                       0.612410   \n",
       "\n",
       "   question_multi_intent  ...  question_well_written  answer_helpful  \\\n",
       "0               0.530865  ...               0.919896        0.897294   \n",
       "1               0.139953  ...               0.725094        0.954958   \n",
       "2               0.263809  ...               0.866208        0.919860   \n",
       "3               0.139953  ...               0.669263        0.944348   \n",
       "4               0.254969  ...               0.788498        0.916623   \n",
       "\n",
       "   answer_level_of_information  answer_plausible  answer_relevance  \\\n",
       "0                     0.406054          0.957358          0.956077   \n",
       "1                     0.624564          0.976141          0.964589   \n",
       "2                     0.557448          0.976141          0.964589   \n",
       "3                     0.656321          0.976141          0.964589   \n",
       "4                     0.641902          0.972269          0.962273   \n",
       "\n",
       "   answer_satisfaction  answer_type_instructions  answer_type_procedure  \\\n",
       "0             0.736326                  0.091482               0.027052   \n",
       "1             0.870414                  0.901102               0.173739   \n",
       "2             0.803503                  0.091482               0.043473   \n",
       "3             0.890407                  0.790419               0.199159   \n",
       "4             0.841106                  0.153972               0.076906   \n",
       "\n",
       "   answer_type_reason_explanation  answer_well_written  \n",
       "0                        0.857635             0.946178  \n",
       "1                        0.155895             0.883272  \n",
       "2                        0.863898             0.929245  \n",
       "3                        0.649088             0.901653  \n",
       "4                        0.699780             0.914850  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xlnet_test_inputs = inputs = (\n",
    "                    data['xlnet_test_a'][tags[0]], data['xlnet_test_t_q'][tags[0]], \n",
    "    data['xlnet_test_a'][tags[1]], \n",
    "    data['xlnet_test_t_q'][tags[1]],data['xlnet_test_a'][tags[2]], data['xlnet_test_t_q'][tags[2]]  \n",
    "                  \n",
    "                 )\n",
    "bert_test_inputs = inputs = (\n",
    "                    data['bert_test_a'][tags[0]], data['bert_test_t_q'][tags[0]], \n",
    "    data['bert_test_a'][tags[1]], \n",
    "    data['bert_test_t_q'][tags[1]],data['bert_test_a'][tags[2]], data['bert_test_t_q'][tags[2]]  \n",
    "                  \n",
    "                 )\n",
    "xlnet_test_preds = xlnet_model.predict(xlnet_test_inputs)\n",
    "bert_test_preds = bert_model.predict(bert_test_inputs)\n",
    "mean_test_preds = 0.5*xlnet_test_preds + 0.5*bert_test_preds\n",
    "post_test_preds = opt.transform(mean_test_preds)\n",
    "\n",
    "submission = pd.read_csv(DIR+'/sample_submission.csv')\n",
    "submission.iloc[:,1:] = post_test_preds\n",
    "submission.to_csv(\"submission.csv\", index = False)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 1.881597,
     "end_time": "2020-08-25T14:56:01.281543",
     "exception": false,
     "start_time": "2020-08-25T14:55:59.399946",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* Private Score - 0.38023 | Public Score - 0.40135\n",
    "* Top 10% in private submission | Top 11% in public subsmission\n",
    "* Here is the kernel - https://www.kaggle.com/varunsaproo/xlnet-based?scriptVersionId=41365639 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 5556.999511,
   "end_time": "2020-08-25T14:56:04.505159",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-08-25T13:23:27.505648",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
