{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "papermill": {
      "duration": 1388.340049,
      "end_time": "2020-09-23T05:29:40.004484",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2020-09-23T05:06:31.664435",
      "version": "2.1.0"
    },
    "colab": {
      "name": "cnn-lstm.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARw1Yk5MDfZ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install fuzzywuzzy\n",
        "!pip3 install transformers==2.11.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2020-09-23T05:06:36.242976Z",
          "iopub.status.busy": "2020-09-23T05:06:36.242015Z",
          "iopub.status.idle": "2020-09-23T05:06:36.273576Z",
          "shell.execute_reply": "2020-09-23T05:06:36.272924Z"
        },
        "papermill": {
          "duration": 0.070142,
          "end_time": "2020-09-23T05:06:36.273682",
          "exception": false,
          "start_time": "2020-09-23T05:06:36.203540",
          "status": "completed"
        },
        "tags": [],
        "id": "FevNP76dDVNc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as snb\n",
        "import warnings\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import os\n",
        "import string\n",
        "from gensim.models import KeyedVectors, Word2Vec\n",
        "from collections import Counter\n",
        "from textblob import TextBlob\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from fuzzywuzzy import fuzz\n",
        "from collections import Counter\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import GroupKFold\n",
        "import tensorflow_hub as hub\n",
        "import random as rn\n",
        "from scipy.stats import spearmanr\n",
        "from transformers import XLNetConfig, TFXLNetModel, XLNetTokenizer, TFXLNetMainLayer\n",
        "SEED = 21\n",
        "os.environ['PYTHONHASHSEED']=str(SEED)\n",
        "os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GXWNgRTQrPh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "dc1cfe9c-c4c5-4f95-a1cc-161b4f3c91a1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QmsEaDiEnGD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if os.getcwd() != '/content/drive/My Drive/google_qa':\n",
        "    os.chdir('./drive/My Drive/google_qa')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-09-23T05:06:49.351424Z",
          "iopub.status.busy": "2020-09-23T05:06:49.346170Z",
          "iopub.status.idle": "2020-09-23T05:06:49.359681Z",
          "shell.execute_reply": "2020-09-23T05:06:49.359059Z"
        },
        "papermill": {
          "duration": 0.059284,
          "end_time": "2020-09-23T05:06:49.359788",
          "exception": false,
          "start_time": "2020-09-23T05:06:49.300504",
          "status": "completed"
        },
        "tags": [],
        "id": "VmKSQ4O1DVNr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class XLNet(TFXLNetModel):\n",
        "    def __init__(self, config, *inputs, **kwrgs):\n",
        "        super(XLNet, self).__init__(config, *inputs, **kwrgs)\n",
        "        self.transformer = TFXLNetMainLayer(config, name = 'transformer')\n",
        "        for i in range(1, 3):\n",
        "            self.transformer.layer[-i].trainable = False\n",
        "    def call(self, inputs, **kwrgs):\n",
        "        outputs = self.transformer(inputs)\n",
        "        hidden_states = outputs[1]\n",
        "        h12 = hidden_states[-1][:, 0, :]\n",
        "        h11 = hidden_states[-2][:, 0, :]\n",
        "        h10 = hidden_states[-3][:, 0, :]\n",
        "        h9 = hidden_states[-4][:, 0, :]\n",
        "        concat = tf.keras.layers.Concatenate(axis = -1)([h9, h10, h11, h12])\n",
        "        return concat\n",
        "def transformer_model():\n",
        "    id_1 = tf.keras.Input(shape = (512), dtype = tf.int32)\n",
        "    id_2 = tf.keras.Input(shape = (512), dtype = tf.int32)\n",
        "\n",
        "    type_id_1 = tf.keras.Input(shape = (512), dtype = tf.int32)\n",
        "    type_id_2 = tf.keras.Input(shape = (512), dtype = tf.int32)\n",
        "        \n",
        "    a1 = tf.keras.Input(shape = (512), dtype = tf.int32)\n",
        "    a2 = tf.keras.Input(shape = (512), dtype = tf.int32)\n",
        "\n",
        "    config = XLNetConfig.from_pretrained('xlnet/config-xlnet-base-cased', output_hidden_states = True)\n",
        "    transformer = XLNet.from_pretrained('xlnet/model-xlnet-base-cased', config = config)\n",
        "                                                \n",
        "\n",
        "    out_1 = transformer({'input_ids':id_1, 'attention_mask':a1, 'token_type_ids':type_id_1})\n",
        "    out_2 = transformer({'input_ids':id_2, 'attention_mask':a2, 'token_type_ids':type_id_2})\n",
        "    \n",
        "    concat = tf.keras.layers.Concatenate(axis = -1)([out_1, out_2])\n",
        "    drop = tf.keras.layers.Dropout(rate = 0.1)(concat)\n",
        "    dense = tf.keras.layers.Dense(30, activation = 'sigmoid')(drop)\n",
        "    \n",
        "    return tf.keras.Model(inputs = [id_1, id_2, type_id_1, type_id_2, a1, a2], outputs = [dense])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-09-23T05:07:12.399789Z",
          "iopub.status.busy": "2020-09-23T05:07:12.399143Z",
          "iopub.status.idle": "2020-09-23T05:07:12.472564Z",
          "shell.execute_reply": "2020-09-23T05:07:12.471945Z"
        },
        "papermill": {
          "duration": 0.110036,
          "end_time": "2020-09-23T05:07:12.472681",
          "exception": false,
          "start_time": "2020-09-23T05:07:12.362645",
          "status": "completed"
        },
        "tags": [],
        "id": "pLxOdLabDVNx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xlnet_tokenizer = XLNetTokenizer.from_pretrained('xlnet/tokenizer')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-09-23T05:07:12.543730Z",
          "iopub.status.busy": "2020-09-23T05:07:12.542971Z",
          "iopub.status.idle": "2020-09-23T05:07:12.726555Z",
          "shell.execute_reply": "2020-09-23T05:07:12.725937Z"
        },
        "papermill": {
          "duration": 0.220981,
          "end_time": "2020-09-23T05:07:12.726668",
          "exception": false,
          "start_time": "2020-09-23T05:07:12.505687",
          "status": "completed"
        },
        "tags": [],
        "id": "7cLziDjUDVN2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-09-23T05:07:12.822895Z",
          "iopub.status.busy": "2020-09-23T05:07:12.807338Z",
          "iopub.status.idle": "2020-09-23T05:08:14.401112Z",
          "shell.execute_reply": "2020-09-23T05:08:14.400455Z"
        },
        "papermill": {
          "duration": 61.641493,
          "end_time": "2020-09-23T05:08:14.401258",
          "exception": false,
          "start_time": "2020-09-23T05:07:12.759765",
          "status": "completed"
        },
        "tags": [],
        "id": "ZPX8f99CDVN6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize_input(tokenizer, s1, s2, tags, data_name, max_length, tokenizer_name = 'bert'):\n",
        "  if s2 is not None:\n",
        "    x = tokenizer.encode_plus(s1, s2, pad_to_max_length=False)\n",
        "    if len(x['input_ids']) > max_length:\n",
        "      segment_1 = int(0.25*max_length)\n",
        "      x['input_ids'] = x['input_ids'][:segment_1] + x['input_ids'][-(max_length-segment_1):]\n",
        "      x['attention_mask'] = x['attention_mask'][:segment_1] + x['attention_mask'][-(max_length-segment_1):]\n",
        "      x['token_type_ids'] = x['token_type_ids'][:segment_1] + x['token_type_ids'][-(max_length-segment_1):]\n",
        "    else:\n",
        "      diff = max_length - len(x['input_ids'])\n",
        "      if tokenizer_name == 'xlnet':\n",
        "        x['input_ids'] = [tokenizer.pad_token_id]*diff + x['input_ids']\n",
        "        x['attention_mask'] = [0]*diff + x['attention_mask']\n",
        "        x['token_type_ids'] = [tokenizer.pad_token_type_id]*diff + x['token_type_ids']\n",
        "      else:\n",
        "        x['input_ids'] = x['input_ids'] + [tokenizer.pad_token_id]*diff\n",
        "        x['attention_mask'] = x['attention_mask'] + [0]*diff\n",
        "        x['token_type_ids'] = x['token_type_ids'] + [0]*diff\n",
        "      \n",
        "  else:\n",
        "    x = tokenizer.encode_plus(s1)\n",
        "    if len(x['input_ids']) > max_length:\n",
        "      segment_1 = int(0.25*max_length)\n",
        "      x['input_ids'] = x['input_ids'][:segment_1] + x['input_ids'][-(max_length-segment_1):]\n",
        "      x['attention_mask'] = x['attention_mask'][:segment_1] + x['attention_mask'][-(max_length-segment_1):]\n",
        "      x['token_type_ids'] = x['token_type_ids'][:segment_1] + x['token_type_ids'][-(max_length-segment_1):]\n",
        "    else:\n",
        "      diff = max_length - len(x['input_ids'])\n",
        "      if tokenizer_name == 'xlnet':\n",
        "        x['input_ids'] = [tokenizer.pad_token_id]*diff + x['input_ids']\n",
        "        x['attention_mask'] = [0]*diff + x['attention_mask']\n",
        "        x['token_type_ids'] = [tokenizer.pad_token_type_id]*diff + x['token_type_ids']\n",
        "      else:\n",
        "        x['input_ids'] = x['input_ids'] + [tokenizer.pad_token_id]*diff\n",
        "        x['attention_mask'] = x['attention_mask'] + [0]*diff\n",
        "        x['token_type_ids'] = x['token_type_ids'] + [tokenizer.pad_token_type_id]*diff\n",
        "  \n",
        "  data[data_name][tags[0]].append(x['input_ids']) \n",
        "  data[data_name][tags[1]].append(x['token_type_ids'])\n",
        "  data[data_name][tags[2]].append(x['attention_mask']) \n",
        "\n",
        "data = {}\n",
        "# ******************************************XLNET*************************************************************************************\n",
        "data['xlnet_train_t_a'] = {}\n",
        "data['xlnet_train_q_a'] = {}\n",
        "data['xlnet_train_t_q'] = {}\n",
        "data['xlnet_train_q'] = {}\n",
        "data['xlnet_train_a'] = {}\n",
        "\n",
        "data['xlnet_test_t_a'] = {}\n",
        "data['xlnet_test_q_a'] = {}\n",
        "data['xlnet_test_t_q'] = {}\n",
        "data['xlnet_test_q'] = {}\n",
        "data['xlnet_test_a'] = {}\n",
        "\n",
        "tags = ['input_ids', 'token_type_ids', 'attention_masks']\n",
        "data['xlnet_train_t_a'][tags[0]], data['xlnet_train_t_a'][tags[1]], data['xlnet_train_t_a'][tags[2]] = [], [], []\n",
        "data['xlnet_train_q_a'][tags[0]], data['xlnet_train_q_a'][tags[1]], data['xlnet_train_q_a'][tags[2]] = [], [], []\n",
        "data['xlnet_train_t_q'][tags[0]], data['xlnet_train_t_q'][tags[1]], data['xlnet_train_t_q'][tags[2]] = [], [], []\n",
        "data['xlnet_train_q'][tags[0]], data['xlnet_train_q'][tags[1]], data['xlnet_train_q'][tags[2]] = [], [], []\n",
        "data['xlnet_train_a'][tags[0]], data['xlnet_train_a'][tags[1]], data['xlnet_train_a'][tags[2]] = [], [], []\n",
        "\n",
        "data['xlnet_test_t_a'][tags[0]], data['xlnet_test_t_a'][tags[1]], data['xlnet_test_t_a'][tags[2]] = [], [], []\n",
        "data['xlnet_test_q_a'][tags[0]], data['xlnet_test_q_a'][tags[1]], data['xlnet_test_q_a'][tags[2]] = [], [], []\n",
        "data['xlnet_test_t_q'][tags[0]], data['xlnet_test_t_q'][tags[1]], data['xlnet_test_t_q'][tags[2]] = [], [], []\n",
        "data['xlnet_test_q'][tags[0]], data['xlnet_test_q'][tags[1]], data['xlnet_test_q'][tags[2]] = [], [], []\n",
        "data['xlnet_test_a'][tags[0]], data['xlnet_test_a'][tags[1]], data['xlnet_test_a'][tags[2]] = [], [], []\n",
        "\n",
        "\n",
        "for i in range(train_df.shape[0]):\n",
        "  tokenize_input(xlnet_tokenizer, train_df.loc[i, 'question_title'], train_df.loc[i, 'answer'], tags, 'xlnet_train_t_a', 512, 'xlnet')\n",
        "  tokenize_input(xlnet_tokenizer, train_df.loc[i, 'question_body'], train_df.loc[i, 'answer'], tags, 'xlnet_train_q_a', 512, 'xlnet')\n",
        "  tokenize_input(xlnet_tokenizer, train_df.loc[i, 'question_title'], train_df.loc[i, 'question_body'], tags, 'xlnet_train_t_q', 512, 'xlnet')\n",
        "  tokenize_input(xlnet_tokenizer, train_df.loc[i, 'question_body'], None, tags, 'xlnet_train_q', 512, 'xlnet')\n",
        "  tokenize_input(xlnet_tokenizer, train_df.loc[i, 'answer'], None, tags, 'xlnet_train_a', 512, 'xlnet')\n",
        "for i in range(test_df.shape[0]):\n",
        "  tokenize_input(xlnet_tokenizer, test_df.loc[i, 'question_title'], test_df.loc[i, 'answer'], tags, 'xlnet_test_t_a', 512, 'xlnet')\n",
        "  tokenize_input(xlnet_tokenizer, test_df.loc[i, 'question_body'], test_df.loc[i, 'answer'], tags, 'xlnet_test_q_a', 512, 'xlnet')\n",
        "  tokenize_input(xlnet_tokenizer, test_df.loc[i, 'question_title'], test_df.loc[i, 'question_body'], tags, 'xlnet_test_t_q', 512, 'xlnet')\n",
        "  tokenize_input(xlnet_tokenizer, test_df.loc[i, 'question_body'], None, tags, 'xlnet_test_q', 512, 'xlnet')\n",
        "  tokenize_input(xlnet_tokenizer, test_df.loc[i, 'answer'], None, tags, 'xlnet_test_a', 512, 'xlnet')\n",
        "\n",
        "for key, _ in data.items():\n",
        "  for k, _ in data[key].items():\n",
        "    data[key][k] = np.array(data[key][k])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-09-23T05:08:14.498525Z",
          "iopub.status.busy": "2020-09-23T05:08:14.482716Z",
          "iopub.status.idle": "2020-09-23T05:08:14.518959Z",
          "shell.execute_reply": "2020-09-23T05:08:14.518382Z"
        },
        "papermill": {
          "duration": 0.083578,
          "end_time": "2020-09-23T05:08:14.519097",
          "exception": false,
          "start_time": "2020-09-23T05:08:14.435519",
          "status": "completed"
        },
        "tags": [],
        "id": "Efbyj-8nDVN9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''Some contractions, rules and token replace dictionaries which will help in text preprocessing'''\n",
        "contractions = {\n",
        "\"ain't\": \"is not\",\n",
        "\"aren't\": \"are not\",\n",
        "\"can't\": \"cannot\",\n",
        "\"can't've\": \"cannot have\",\n",
        "\"'cause\": \"because\",\n",
        "\"could've\": \"could have\",\n",
        "\"couldn't\": \"could not\",\n",
        "\"couldn't've\": \"could not have\",\n",
        "\"didn't\": \"did not\",\n",
        "\"doesn't\": \"does not\",\n",
        "\"don't\": \"do not\",\n",
        "\"hadn't\": \"had not\",\n",
        "\"hadn't've\": \"had not have\",\n",
        "\"hasn't\": \"has not\",\n",
        "\"haven't\": \"have not\",\n",
        "\"he'd\": \"he would\",\n",
        "\"he'd've\": \"he would have\",\n",
        "\"he'll\": \"he will\",\n",
        "\"he'll've\": \"he he will have\",\n",
        "\"he's\": \"he is\",\n",
        "\"how'd\": \"how did\",\n",
        "\"how'd'y\": \"how do you\",\n",
        "\"how'll\": \"how will\",\n",
        "\"how's\": \"how is\",\n",
        "\"I'd\": \"I would\",\n",
        "\"i'd've\": \"I would have\",\n",
        "\"i'll\": \"I will\",\n",
        "\"i'll've\": \"I will have\",\n",
        "\"i'm\": \"I am\",\n",
        "\"i've\": \"I have\",\n",
        "\"i'd\": \"i would\",\n",
        "\"i'd've\": \"i would have\",\n",
        "\"i'll\": \"i will\",\n",
        "\"i'll've\": \"i will have\",\n",
        "\"i'm\": \"i am\",\n",
        "\"i've\": \"i have\",\n",
        "\"isn't\": \"is not\",\n",
        "\"its\":\"it is\",\n",
        "\"it'd\": \"it would\",\n",
        "\"it'd've\": \"it would have\",\n",
        "\"it'll\": \"it will\",\n",
        "\"it'll've\": \"it will have\",\n",
        "\"it's\": \"it is\",\n",
        "\"let's\": \"let us\",\n",
        "\"ma'am\": \"madam\",\n",
        "\"mayn't\": \"may not\",\n",
        "\"might've\": \"might have\",\n",
        "\"mightn't\": \"might not\",\n",
        "\"mightn't've\": \"might not have\",\n",
        "\"must've\": \"must have\",\n",
        "\"mustn't\": \"must not\",\n",
        "\"mustn't've\": \"must not have\",\n",
        "\"needn't\": \"need not\",\n",
        "\"needn't've\": \"need not have\",\n",
        "\"o'clock\": \"of the clock\",\n",
        "\"oughtn't\": \"ought not\",\n",
        "\"oughtn't've\": \"ought not have\",\n",
        "\"shan't\": \"shall not\",\n",
        "\"sha'n't\": \"shall not\",\n",
        "\"shan't've\": \"shall not have\",\n",
        "\"she'd\": \"she would\",\n",
        "\"she'd've\": \"she would have\",\n",
        "\"she'll\": \"she will\",\n",
        "\"she'll've\": \"she will have\",\n",
        "\"she's\": \"she is\",\n",
        "\"should've\": \"should have\",\n",
        "\"shouldn't\": \"should not\",\n",
        "\"shouldn't've\": \"should not have\",\n",
        "\"so've\": \"so have\",\n",
        "\"so's\": \"so as\",\n",
        "\"that'd\": \"that would\",\n",
        "\"that'd've\": \"that would have\",\n",
        "\"that's\": \"that is\",\n",
        "\"there'd\": \"there would\",\n",
        "\"there'd've\": \"there would have\",\n",
        "\"there's\": \"there is\",\n",
        "\"they'd\": \"they would\",\n",
        "\"they'd've\": \"they would have\",\n",
        "\"they'll\": \"they will\",\n",
        "\"they'll've\": \"they will have\",\n",
        "\"they're\": \"they are\",\n",
        "\"they've\": \"they have\",\n",
        "\"to've\": \"to have\",\n",
        "\"wasn't\": \"was not\",\n",
        "\"we'd\": \"we would\",\n",
        "\"we'd've\": \"we would have\",\n",
        "\"we'll\": \"we will\",\n",
        "\"we'll've\": \"we will have\",\n",
        "\"we're\": \"we are\",\n",
        "\"we've\": \"we have\",\n",
        "\"weren't\": \"were not\",\n",
        "\"what'll\": \"what will\",\n",
        "\"what'll've\": \"what will have\",\n",
        "\"what're\": \"what are\",\n",
        "\"what's\": \"what is\",\n",
        "\"what've\": \"what have\",\n",
        "\"when's\": \"when is\",\n",
        "\"when've\": \"when have\",\n",
        "\"where'd\": \"where did\",\n",
        "\"where's\": \"where is\",\n",
        "\"where've\": \"where have\",\n",
        "\"who'll\": \"who will\",\n",
        "\"who'll've\": \"who will have\",\n",
        "\"who's\": \"who is\",\n",
        "\"who've\": \"who have\",\n",
        "\"why's\": \"why is\",\n",
        "\"why've\": \"why have\",\n",
        "\"will've\": \"will have\",\n",
        "\"won't\": \"will not\",\n",
        "\"won't've\": \"will not have\",\n",
        "\"would've\": \"would have\",\n",
        "\"wouldn't\": \"would not\",\n",
        "\"wouldn't've\": \"would not have\",\n",
        "\"y'all\": \"you all\",\n",
        "\"y'all'd\": \"you all would\",\n",
        "\"y'all'd've\": \"you all would have\",\n",
        "\"y'all're\": \"you all are\",\n",
        "\"y'all've\": \"you all have\",\n",
        "\"you'd\": \"you would\",\n",
        "\"you'd've\": \"you would have\",\n",
        "\"you'll\": \"you will\",\n",
        "\"you'll've\": \"you will have\",\n",
        "\"you're\": \"you are\",\n",
        "\"you've\": \"you have\"\n",
        "}\n",
        "\n",
        "rules = {\n",
        "    \"'t\": \" not\",\n",
        "    \"'cause\": \" because\",\n",
        "    \"'ve\": \" have\",\n",
        "    \"'t\": \" not\",\n",
        "    \"'s\": \" is\",\n",
        "    \"'d\": \" had\"\n",
        "}\n",
        "\n",
        "punctuations = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", \n",
        "                '$', '&', '/', '[', ']','>', '%', '=', '#', '*', '+', '\\\\', '•', '~', \n",
        "                '@', '£', '·', '_', '{', '}', '©', '^','®', '`', '<', '→', '°', '€', '™', \n",
        "                '›', '♥', '←', '×', '§', '″', '′', 'Â', '█','½', 'à', '…', '“', '★', '”', \n",
        "                '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶','↑', '±', '¿', '▾', '═', \n",
        "                '¦', '║', '―', '¥', '▓', '—', '‹', '─', '▒', '：', '¼','⊕', '▼', '▪', '†',\n",
        "                '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲','è', '¸', '¾', \n",
        "                'Ã', '⋅', '‘', '∞', '∙', '）', '↓', '、', '│', '（', '»', '，', '♪','╩', \n",
        "                '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', \n",
        "                'ï', 'Ø', '¹', '≤', '‡', '√'] + list(string.punctuation)\n",
        "token_replace = {\n",
        "    'usepackage':'latex',\n",
        "    'orf19':'gene',\n",
        "    'documentclass':'latex',\n",
        "    'magento':'open-source e-commerce',\n",
        "    'appium':'web-app',\n",
        "    'tikz':'programming language',\n",
        "    'tikzpicture':'programming language',\n",
        "    'openvpn':'vpn',\n",
        "    'httpclient':'http client',\n",
        "    'arraylist':'array list',\n",
        "    'jsonobject': 'json',\n",
        "    'artifactid':'xml',\n",
        "    'hwnd':'os'\n",
        "}\n",
        "punctuations_in_embeddings = {',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']', \n",
        "                '>', '%', '=', '#', '*', '+', '\\\\', '•', '~', '@', '£', '·', '{', '}', '©', '^', '®', \n",
        "                '<', '→', '°', '€', '™', '›', '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', \n",
        "                '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '═', \n",
        "                '¦', '║', '―', '¥', '▓', '—', '‹', '─', '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', \n",
        "                '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', \n",
        "                '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔',\n",
        "                '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', \n",
        "                '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '{', \n",
        "                '|', '}', '~'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-09-23T05:08:14.600913Z",
          "iopub.status.busy": "2020-09-23T05:08:14.599937Z",
          "iopub.status.idle": "2020-09-23T05:08:14.602253Z",
          "shell.execute_reply": "2020-09-23T05:08:14.602935Z"
        },
        "papermill": {
          "duration": 0.050299,
          "end_time": "2020-09-23T05:08:14.603089",
          "exception": false,
          "start_time": "2020-09-23T05:08:14.552790",
          "status": "completed"
        },
        "tags": [],
        "id": "iyWNSdyDDVN_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''Pipeline for text preprocessing. Check coverage computes what %age of tokens in the text data \n",
        "are covered by Embeddings.\n",
        "preprocess_text is used to clean text.\n",
        "'''\n",
        "def improve_text(dframes):\n",
        "    def preprocess_text(s):\n",
        "        s = s.lower()\n",
        "        '''Expanding contractions...'''\n",
        "        for key, value in contractions.items():\n",
        "            s = s.replace(key, f' {value} ')\n",
        "        for key, value in rules.items():\n",
        "            s = s.replace(key, f' {value} ')\n",
        "        '''Fixing punctuations...'''\n",
        "        for punct in punctuations:\n",
        "            if punct in punctuations_in_embeddings:\n",
        "                s = s.replace(punct, f' {punct} ')\n",
        "            else:\n",
        "                s = s.replace(punct, ' ')\n",
        "        '''Replacing few tokens with its similar word/group of words...'''\n",
        "        for key, value in token_replace.items():\n",
        "            s = s.replace(key, value)\n",
        "        '''Removing HTML tags'''\n",
        "        s = re.sub('<.*?>', ' ', s)\n",
        "        s = re.sub('\\s+', ' ', s)\n",
        "        return s\n",
        "    print(\"Applying Preprocessing.....\")\n",
        "    for each_df in dframes:\n",
        "        each_df['clean_title'] = each_df['question_title'].apply(preprocess_text)\n",
        "        each_df['clean_question_body'] = each_df['question_body'].apply(preprocess_text)\n",
        "        each_df['clean_answer'] = each_df['answer'].apply(preprocess_text)\n",
        "    print(\"Preprocessing Finished\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-09-23T05:08:14.701007Z",
          "iopub.status.busy": "2020-09-23T05:08:14.695455Z",
          "iopub.status.idle": "2020-09-23T05:08:20.508534Z",
          "shell.execute_reply": "2020-09-23T05:08:20.507094Z"
        },
        "papermill": {
          "duration": 5.871585,
          "end_time": "2020-09-23T05:08:20.508686",
          "exception": false,
          "start_time": "2020-09-23T05:08:14.637101",
          "status": "completed"
        },
        "tags": [],
        "id": "wz2xktd2DVOC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "improve_text([train_df, test_df])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-09-23T05:08:20.601809Z",
          "iopub.status.busy": "2020-09-23T05:08:20.596290Z",
          "iopub.status.idle": "2020-09-23T05:08:20.604941Z",
          "shell.execute_reply": "2020-09-23T05:08:20.604411Z"
        },
        "papermill": {
          "duration": 0.061796,
          "end_time": "2020-09-23T05:08:20.605082",
          "exception": false,
          "start_time": "2020-09-23T05:08:20.543286",
          "status": "completed"
        },
        "tags": [],
        "id": "VmpKmThNDVOG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fetch_words(s, use_stopwords = False, ignore_stopwords = False):\n",
        "    if ignore_stopwords == True:\n",
        "        return {word for word in s.split() if word not in stop_words}\n",
        "    elif use_stopwords:\n",
        "        return {word for word in s.split() if word in stop_words}\n",
        "    else:\n",
        "        return set(s.split())\n",
        "def text_features(row, use_stopwords, is_token, return_max):\n",
        "    t1, t2 = None, None\n",
        "    if use_stopwords == True:\n",
        "        t1 = fetch_words(row[0], use_stopwords = True)\n",
        "        t2 = fetch_words(row[1], use_stopwords = True)\n",
        "    elif is_token == True:\n",
        "        t1 = fetch_words(row[0], ignore_stopwords = True)\n",
        "        t2 = fetch_words(row[1], ignore_stopwords = True)\n",
        "    else:\n",
        "        t1 = fetch_words(row[0])\n",
        "        t2 = fetch_words(row[1])\n",
        "    if return_max:\n",
        "        try:\n",
        "            ans = len(t1.intersection(t2))/max(len(t1), len(t2))\n",
        "        except:\n",
        "            return 0\n",
        "    else:\n",
        "        try:\n",
        "            ans = len(t1.intersection(t2))/min(len(t1), len(t2))\n",
        "        except:\n",
        "            return 0\n",
        "    return ans\n",
        "\n",
        "def get_ratio(row, is_token = False):\n",
        "    if is_token == True:\n",
        "        t1 = len(set([word for word in row[0].split() if word not in stop_words]))\n",
        "        t2 = len(set([word for word in row[1].split() if word not in stop_words]))\n",
        "    t1 = len(set([word for word in row[0].split()]))\n",
        "    t2 = len(set([word for word in row[1].split()]))\n",
        "    try:\n",
        "        return t1/t2\n",
        "    except:\n",
        "        return 0\n",
        "def get_fuzzy_ratio(row, ratio, partial_ratio, token_sort_ratio, token_set_ratio):\n",
        "    if ratio:\n",
        "        return fuzz.ratio(row[0], row[1])/100\n",
        "    elif partial_ratio:\n",
        "        return fuzz.partial_ratio(row[0], row[1])/100\n",
        "    elif token_sort_ratio:\n",
        "        return fuzz.token_sort_ratio(row[0], row[1])/100\n",
        "    else:\n",
        "        return fuzz.token_set_ratio(row[0], row[1])/100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-09-23T05:08:20.686626Z",
          "iopub.status.busy": "2020-09-23T05:08:20.684730Z",
          "iopub.status.idle": "2020-09-23T05:08:20.687283Z",
          "shell.execute_reply": "2020-09-23T05:08:20.687776Z"
        },
        "papermill": {
          "duration": 0.047775,
          "end_time": "2020-09-23T05:08:20.687919",
          "exception": false,
          "start_time": "2020-09-23T05:08:20.640144",
          "status": "completed"
        },
        "tags": [],
        "id": "-wxjcbs2DVOJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature_engg_cols = ['cwc_min_title_question_body',\n",
        "       'cwc_max_title_question_body', 'csc_min_title_question_body',\n",
        "       'csc_max_title_question_body', 'ctc_min_title_question_body',\n",
        "       'ctc_max_title_question_body', 'cwc_min_title_answer',\n",
        "       'cwc_max_title_answer', 'csc_min_title_answer', 'csc_max_title_answer',\n",
        "       'ctc_min_title_answer', 'ctc_max_title_answer',\n",
        "       'cwc_min_question_body_answer', 'cwc_max_question_body_answer',\n",
        "       'csc_min_question_body_answer', 'csc_max_question_body_answer',\n",
        "       'ctc_min_question_body_answer', 'ctc_max_question_body_answer',\n",
        "       'word_title_question_body_ratio', 'token_title_question_body_ratio',\n",
        "       'word_question_body_answer_ratio', 'token_question_body_answer_ratio',\n",
        "       'word_title_answer_ratio', 'token_title_answer_ratio',\n",
        "       'ratio_title_question_body', 'partial_ratio_title_question_body',\n",
        "       'token_sort_ratio_title_question_body',\n",
        "       'token_set_ratio_title_question_body', 'ratio_question_body_answer',\n",
        "       'partial_ratio_question_body_answer',\n",
        "       'token_sort_ratio_question_body_answer',\n",
        "       'token_set_ratio_question_body_answer', 'ratio_title_answer',\n",
        "       'partial_ratio_title_answer', 'token_sort_ratio_title_answer',\n",
        "       'token_set_ratio_title_answer', 'question_title_polarity', 'question_body_polarity', 'answer_polarity']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-09-23T05:08:20.771079Z",
          "iopub.status.busy": "2020-09-23T05:08:20.770343Z",
          "iopub.status.idle": "2020-09-23T05:08:47.113254Z",
          "shell.execute_reply": "2020-09-23T05:08:47.112577Z"
        },
        "papermill": {
          "duration": 26.390931,
          "end_time": "2020-09-23T05:08:47.113386",
          "exception": false,
          "start_time": "2020-09-23T05:08:20.722455",
          "status": "completed"
        },
        "tags": [],
        "id": "5ctvNvDCDVOM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_polarity(s):\n",
        "    return TextBlob(s).sentiment.polarity\n",
        "train_df['question_title_polarity'] = train_df.clean_title.apply(get_polarity)\n",
        "train_df['question_body_polarity'] = train_df.clean_question_body.apply(get_polarity)\n",
        "train_df['answer_polarity'] = train_df.clean_answer.apply(get_polarity)\n",
        "test_df['question_title_polarity'] = test_df.clean_title.apply(get_polarity)\n",
        "test_df['question_body_polarity'] = test_df.clean_question_body.apply(get_polarity)\n",
        "test_df['answer_polarity'] = test_df.clean_answer.apply(get_polarity)\n",
        "##################################################################################################################\n",
        "train_df['question_title_count'] = train_df.clean_title.apply(lambda x: len(x.split()))\n",
        "train_df['question_body_count'] = train_df.clean_question_body.apply(lambda x: len(x.split()))\n",
        "train_df['answer_count'] = train_df.clean_answer.apply(lambda x: len(x.split()))\n",
        "test_df['question_title_count'] = test_df.clean_title.apply(lambda x: len(x.split()))\n",
        "test_df['question_body_count'] = test_df.clean_question_body.apply(lambda x: len(x.split()))\n",
        "test_df['answer_count'] = test_df.clean_answer.apply(lambda x: len(x.split()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-09-23T05:08:47.222634Z",
          "iopub.status.busy": "2020-09-23T05:08:47.206734Z",
          "iopub.status.idle": "2020-09-23T05:16:07.938198Z",
          "shell.execute_reply": "2020-09-23T05:16:07.937403Z"
        },
        "papermill": {
          "duration": 440.788204,
          "end_time": "2020-09-23T05:16:07.938319",
          "exception": false,
          "start_time": "2020-09-23T05:08:47.150115",
          "status": "completed"
        },
        "tags": [],
        "id": "piIKpP-qDVOP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##################################        TRAIN        ############################################################\n",
        "train_df['cwc_min_title_question_body'] = train_df[['clean_title', 'clean_question_body']].apply(func = text_features, \n",
        "                                                axis = 1, args = (False, False, False))\n",
        "train_df['cwc_max_title_question_body'] = train_df[['clean_title', 'clean_question_body']].apply(func = text_features, \n",
        "                                                axis = 1, args = (False, False, True))\n",
        "train_df['csc_min_title_question_body'] = train_df[['clean_title', 'clean_question_body']].apply(func = text_features, \n",
        "                                                axis = 1, args = (True, False, False))\n",
        "train_df['csc_max_title_question_body'] = train_df[['clean_title', 'clean_question_body']].apply(func = text_features, \n",
        "                                                axis = 1, args = (True, False, True))\n",
        "train_df['ctc_min_title_question_body'] = train_df[['clean_title', 'clean_question_body']].apply(func = text_features, \n",
        "                                                axis = 1, args = (False, True, False))\n",
        "train_df['ctc_max_title_question_body'] = train_df[['clean_title', 'clean_question_body']].apply(func = text_features, \n",
        "                                                axis = 1, args = (False, True, True))\n",
        "train_df['cwc_min_title_answer'] = train_df[['clean_title', 'clean_answer']].apply(func = text_features, \n",
        "                                                axis = 1, args = (False, False, False))\n",
        "train_df['cwc_max_title_answer'] = train_df[['clean_title', 'clean_answer']].apply(func = text_features, \n",
        "                                                axis = 1, args = (False, False, True))\n",
        "train_df['csc_min_title_answer'] = train_df[['clean_title', 'clean_answer']].apply(func = text_features, \n",
        "                                                axis = 1, args = (True, False, False))\n",
        "train_df['csc_max_title_answer'] = train_df[['clean_title', 'clean_answer']].apply(func = text_features, \n",
        "                                                axis = 1, args = (True, False, True))\n",
        "train_df['ctc_min_title_answer'] = train_df[['clean_title', 'clean_answer']].apply(func = text_features, \n",
        "                                                axis = 1, args = (False, True, False))\n",
        "train_df['ctc_max_title_answer'] = train_df[['clean_title', 'clean_answer']].apply(func = text_features, \n",
        "                                                axis = 1, args = (False, True, True))\n",
        "train_df['cwc_min_question_body_answer'] = train_df[['clean_question_body', 'clean_answer']].apply(func = text_features, \n",
        "                                                axis = 1, args = (False, False, False))\n",
        "train_df['cwc_max_question_body_answer'] = train_df[['clean_question_body', 'clean_answer']].apply(func = text_features, \n",
        "                                                axis = 1, args = (False, False, True))\n",
        "train_df['csc_min_question_body_answer'] = train_df[['clean_question_body', 'clean_answer']].apply(func = text_features, \n",
        "                                                axis = 1, args = (True, False, False))\n",
        "train_df['csc_max_question_body_answer'] = train_df[['clean_question_body', 'clean_answer']].apply(func = text_features, \n",
        "                                                axis = 1, args = (True, False, True))\n",
        "train_df['ctc_min_question_body_answer'] = train_df[['clean_question_body', 'clean_answer']].apply(func = text_features, \n",
        "                                                axis = 1, args = (False, True, False))\n",
        "train_df['ctc_max_question_body_answer'] = train_df[['clean_question_body', 'clean_answer']].apply(func = text_features, \n",
        "                                                axis = 1, args = (False, True, True))\n",
        "\n",
        "train_df['word_title_question_body_ratio'] = train_df[['clean_title', 'clean_question_body']].apply(\n",
        "    func = get_ratio, axis = 1, args = (False, ))\n",
        "train_df['token_title_question_body_ratio'] = train_df[['clean_title', 'clean_question_body']].apply(\n",
        "    func = get_ratio, axis = 1, args = (True, ))\n",
        "train_df['word_question_body_answer_ratio'] = train_df[['clean_question_body', 'clean_answer']].apply(\n",
        "    func = get_ratio, axis = 1, args = (False, ))\n",
        "train_df['token_question_body_answer_ratio'] = train_df[['clean_question_body', 'clean_answer']].apply(\n",
        "    func = get_ratio, axis = 1, args = (True, ))\n",
        "train_df['word_title_answer_ratio'] = train_df[['clean_title', 'clean_answer']].apply(func = get_ratio, \n",
        "                                                axis = 1, args = (False, ))\n",
        "train_df['token_title_answer_ratio'] = train_df[['clean_title', 'clean_answer']].apply(func = get_ratio, \n",
        "                                                axis = 1, args = (True, ))\n",
        "\n",
        "train_df['ratio_title_question_body'] = \\\n",
        "train_df[['clean_title', 'clean_question_body']].apply(func = get_fuzzy_ratio, \n",
        "                                                 axis = 1, args = (True, False, False, False))\n",
        "train_df['partial_ratio_title_question_body'] = \\\n",
        "train_df[['clean_title', 'clean_question_body']].apply(func = get_fuzzy_ratio, \n",
        "                                                 axis = 1, args = (False, True, False, False))\n",
        "train_df['token_sort_ratio_title_question_body'] = \\\n",
        "train_df[['clean_title', 'clean_question_body']].apply(func = get_fuzzy_ratio, \n",
        "                                                 axis = 1, args = (False, False, True, False))\n",
        "train_df['token_set_ratio_title_question_body'] = \\\n",
        "train_df[['clean_title', 'clean_question_body']].apply(func = get_fuzzy_ratio, \n",
        "                                                 axis = 1, args = (False, False, False, True))\n",
        "train_df['ratio_question_body_answer'] = \\\n",
        "train_df[['clean_question_body', 'clean_answer']].apply(func = get_fuzzy_ratio, \n",
        "                                                 axis = 1, args = (True, False, False, False ))\n",
        "train_df['partial_ratio_question_body_answer'] = \\\n",
        "train_df[['clean_question_body', 'clean_answer']].apply(func = get_fuzzy_ratio, \n",
        "                                                 axis = 1, args = (False, True, False, False))\n",
        "train_df['token_sort_ratio_question_body_answer'] = \\\n",
        "train_df[['clean_question_body', 'clean_answer']].apply(func = get_fuzzy_ratio, \n",
        "                                                 axis = 1, args = (False, False, True, False))\n",
        "train_df['token_set_ratio_question_body_answer'] = \\\n",
        "train_df[['clean_question_body', 'clean_answer']].apply(func = get_fuzzy_ratio, \n",
        "                                                 axis = 1, args = (False, False, False, True))\n",
        "train_df['ratio_title_answer'] = \\\n",
        "train_df[['clean_title', 'clean_answer']].apply(func = get_fuzzy_ratio, \n",
        "                                                 axis = 1, args = (True, False, False, False))\n",
        "train_df['partial_ratio_title_answer'] = \\\n",
        "train_df[['clean_title', 'clean_answer']].apply(func = get_fuzzy_ratio, \n",
        "                                                 axis = 1, args = (False, True, False, False))\n",
        "train_df['token_sort_ratio_title_answer'] = \\\n",
        "train_df[['clean_title', 'clean_answer']].apply(func = get_fuzzy_ratio, \n",
        "                                                 axis = 1, args = (False, False, True, False))\n",
        "train_df['token_set_ratio_title_answer'] = \\\n",
        "train_df[['clean_title', 'clean_answer']].apply(func = get_fuzzy_ratio, \n",
        "                                                 axis = 1, args = (False, False, False, True))\n",
        "\n",
        "##################################        TEST        ############################################################\n",
        "\n",
        "test_df['cwc_min_title_question_body'] = test_df[['clean_title', 'clean_question_body']].apply(func = text_features, \n",
        "                                                axis = 1, args = (False, False, False))\n",
        "test_df['cwc_max_title_question_body'] = test_df[['clean_title', 'clean_question_body']].apply(func = text_features, \n",
        "                                                axis = 1, args = (False, False, True))\n",
        "test_df['csc_min_title_question_body'] = test_df[['clean_title', 'clean_question_body']].apply(func = text_features, \n",
        "                                                axis = 1, args = (True, False, False))\n",
        "test_df['csc_max_title_question_body'] = test_df[['clean_title', 'clean_question_body']].apply(func = text_features, \n",
        "                                                axis = 1, args = (True, False, True))\n",
        "test_df['ctc_min_title_question_body'] = test_df[['clean_title', 'clean_question_body']].apply(func = text_features, \n",
        "                                                axis = 1, args = (False, True, False))\n",
        "test_df['ctc_max_title_question_body'] = test_df[['clean_title', 'clean_question_body']].apply(func = text_features, \n",
        "                                                axis = 1, args = (False, True, True))\n",
        "test_df['cwc_min_title_answer'] = test_df[['clean_title', 'clean_answer']].apply(func = text_features, \n",
        "                                                axis = 1, args = (False, False, False))\n",
        "test_df['cwc_max_title_answer'] = test_df[['clean_title', 'clean_answer']].apply(func = text_features, \n",
        "                                                axis = 1, args = (False, False, True))\n",
        "test_df['csc_min_title_answer'] = test_df[['clean_title', 'clean_answer']].apply(func = text_features, \n",
        "                                                axis = 1, args = (True, False, False))\n",
        "test_df['csc_max_title_answer'] = test_df[['clean_title', 'clean_answer']].apply(func = text_features, \n",
        "                                                axis = 1, args = (True, False, True))\n",
        "test_df['ctc_min_title_answer'] = test_df[['clean_title', 'clean_answer']].apply(func = text_features, \n",
        "                                                axis = 1, args = (False, True, False))\n",
        "test_df['ctc_max_title_answer'] = test_df[['clean_title', 'clean_answer']].apply(func = text_features, \n",
        "                                                axis = 1, args = (False, True, True))\n",
        "test_df['cwc_min_question_body_answer'] = test_df[['clean_question_body', 'clean_answer']].apply(func = text_features, \n",
        "                                                axis = 1, args = (False, False, False))\n",
        "test_df['cwc_max_question_body_answer'] = test_df[['clean_question_body', 'clean_answer']].apply(func = text_features, \n",
        "                                                axis = 1, args = (False, False, True))\n",
        "test_df['csc_min_question_body_answer'] = test_df[['clean_question_body', 'clean_answer']].apply(func = text_features, \n",
        "                                                axis = 1, args = (True, False, False))\n",
        "test_df['csc_max_question_body_answer'] = test_df[['clean_question_body', 'clean_answer']].apply(func = text_features, \n",
        "                                                axis = 1, args = (True, False, True))\n",
        "test_df['ctc_min_question_body_answer'] = test_df[['clean_question_body', 'clean_answer']].apply(func = text_features, \n",
        "                                                axis = 1, args = (False, True, False))\n",
        "test_df['ctc_max_question_body_answer'] = test_df[['clean_question_body', 'clean_answer']].apply(func = text_features, \n",
        "                                                axis = 1, args = (False, True, True))\n",
        "\n",
        "test_df['word_title_question_body_ratio'] = test_df[['clean_title', 'clean_question_body']].apply(\n",
        "    func = get_ratio, axis = 1, args = (False, ))\n",
        "test_df['token_title_question_body_ratio'] = test_df[['clean_title', 'clean_question_body']].apply(\n",
        "    func = get_ratio, axis = 1, args = (True, ))\n",
        "test_df['word_question_body_answer_ratio'] = test_df[['clean_question_body', 'clean_answer']].apply(\n",
        "    func = get_ratio, axis = 1, args = (False, ))\n",
        "test_df['token_question_body_answer_ratio'] = test_df[['clean_question_body', 'clean_answer']].apply(\n",
        "    func = get_ratio, axis = 1, args = (True, ))\n",
        "test_df['word_title_answer_ratio'] = test_df[['clean_title', 'clean_answer']].apply(func = get_ratio, \n",
        "                                                axis = 1, args = (False, ))\n",
        "test_df['token_title_answer_ratio'] = test_df[['clean_title', 'clean_answer']].apply(func = get_ratio, \n",
        "                                                axis = 1, args = (True, ))\n",
        "\n",
        "test_df['ratio_title_question_body'] = \\\n",
        "test_df[['clean_title', 'clean_question_body']].apply(func = get_fuzzy_ratio, \n",
        "                                                 axis = 1, args = (True, False, False, False))\n",
        "test_df['partial_ratio_title_question_body'] = \\\n",
        "test_df[['clean_title', 'clean_question_body']].apply(func = get_fuzzy_ratio, \n",
        "                                                 axis = 1, args = (False, True, False, False))\n",
        "test_df['token_sort_ratio_title_question_body'] = \\\n",
        "test_df[['clean_title', 'clean_question_body']].apply(func = get_fuzzy_ratio, \n",
        "                                                 axis = 1, args = (False, False, True, False))\n",
        "test_df['token_set_ratio_title_question_body'] = \\\n",
        "test_df[['clean_title', 'clean_question_body']].apply(func = get_fuzzy_ratio, \n",
        "                                                 axis = 1, args = (False, False, False, True))\n",
        "test_df['ratio_question_body_answer'] = \\\n",
        "test_df[['clean_question_body', 'clean_answer']].apply(func = get_fuzzy_ratio, \n",
        "                                                 axis = 1, args = (True, False, False, False ))\n",
        "test_df['partial_ratio_question_body_answer'] = \\\n",
        "test_df[['clean_question_body', 'clean_answer']].apply(func = get_fuzzy_ratio, \n",
        "                                                 axis = 1, args = (False, True, False, False))\n",
        "test_df['token_sort_ratio_question_body_answer'] = \\\n",
        "test_df[['clean_question_body', 'clean_answer']].apply(func = get_fuzzy_ratio, \n",
        "                                                 axis = 1, args = (False, False, True, False))\n",
        "test_df['token_set_ratio_question_body_answer'] = \\\n",
        "test_df[['clean_question_body', 'clean_answer']].apply(func = get_fuzzy_ratio, \n",
        "                                                 axis = 1, args = (False, False, False, True))\n",
        "test_df['ratio_title_answer'] = \\\n",
        "test_df[['clean_title', 'clean_answer']].apply(func = get_fuzzy_ratio, \n",
        "                                                 axis = 1, args = (True, False, False, False))\n",
        "test_df['partial_ratio_title_answer'] = \\\n",
        "test_df[['clean_title', 'clean_answer']].apply(func = get_fuzzy_ratio, \n",
        "                                                 axis = 1, args = (False, True, False, False))\n",
        "test_df['token_sort_ratio_title_answer'] = \\\n",
        "test_df[['clean_title', 'clean_answer']].apply(func = get_fuzzy_ratio, \n",
        "                                                 axis = 1, args = (False, False, True, False))\n",
        "test_df['token_set_ratio_title_answer'] = \\\n",
        "test_df[['clean_title', 'clean_answer']].apply(func = get_fuzzy_ratio, \n",
        "                                                 axis = 1, args = (False, False, False, True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wR0fHNSoHti-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_embedding_matrix(vocab, texts, embedd_size, model):\n",
        "  n = len(vocab['token2id'])+1\n",
        "  embedding_matrix = np.zeros((n, embedd_size))\n",
        "  for text in texts:\n",
        "    for key in text:\n",
        "      word = key\n",
        "      try:\n",
        "        embedding_matrix[vocab['token2id'][word]] = model.wv[word]\n",
        "        continue\n",
        "      except:\n",
        "        pass\n",
        "  return embedding_matrix\n",
        "\n",
        "def get_token_ids(texts, max_length):\n",
        "  tokens = []\n",
        "  for text in texts:\n",
        "    tmp_tokens = []\n",
        "    if len(text.split()) > max_length:\n",
        "      for each in (text.split()[:(max_length//2)] + text.split()[-(max_length//2):]):\n",
        "        tmp_tokens.append(vocab['token2id'].get(each, 0))\n",
        "      tokens.append(tmp_tokens)\n",
        "    else:\n",
        "      for each in (text.split()[:max_length]):\n",
        "        tmp_tokens.append(vocab['token2id'].get(each, 0))\n",
        "      tokens.append(tmp_tokens)\n",
        "  return tf.keras.preprocessing.sequence.pad_sequences(tokens, padding=\"post\", maxlen=max_length)\n",
        "\n",
        "train_df['clean_t_q'] = train_df['clean_title'] + ' ' + train_df['clean_question_body']\n",
        "test_df['clean_t_q'] = test_df['clean_title'] + ' ' + test_df['clean_question_body']"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-09-23T05:16:08.008282Z",
          "iopub.status.busy": "2020-09-23T05:16:08.007607Z",
          "iopub.status.idle": "2020-09-23T05:16:08.011881Z",
          "shell.execute_reply": "2020-09-23T05:16:08.011381Z"
        },
        "papermill": {
          "duration": 0.040388,
          "end_time": "2020-09-23T05:16:08.011988",
          "exception": false,
          "start_time": "2020-09-23T05:16:07.971600",
          "status": "completed"
        },
        "tags": [],
        "id": "GexZnzduDVOS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if os.path.exists('embeddings.npz') == False:\n",
        "    train_df['combine_text'] = train_df.clean_title + ' ' + train_df.clean_question_body + ' ' + train_df.clean_answer\n",
        "    test_df['combine_text'] = test_df.clean_title + ' ' + test_df.clean_question_body + ' ' + test_df.clean_answer\n",
        "    all_texts = train_df['combine_text'].tolist() + test_df['combine_text'].tolist()\n",
        "    all_texts = [text.split() for text in all_texts]\n",
        "    model = Word2Vec(size = 300, min_count = 1, window = 5)\n",
        "    model.build_vocab(all_texts)\n",
        "    model.intersect_word2vec_format('../input/embedding-files/fasttext-wiki-news-subwords-300', lockf = 1)\n",
        "    model.train(all_texts, total_examples = model.corpus_count, epochs = 5)\n",
        "    counter = Counter()\n",
        "    for text in all_texts:\n",
        "      counter.update(text)\n",
        "    vocab = {}\n",
        "    vocab['token2id'] = {key:id+1 for id, (key, _) in enumerate(counter.items())}\n",
        "    vocab['id2token'] = {value:key for key, value in vocab['token2id'].items()}\n",
        "    vocab['word_freq'] = dict(counter)\n",
        "    embedding_matrix = build_embedding_matrix(vocab, all_texts, 300, model)\n",
        "else:\n",
        "    file = np.load('embeddings.npz', allow_pickle = True)\n",
        "    vocab = file['a'].tolist()\n",
        "    embedding_matrix = file['b']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-09-23T05:16:37.246665Z",
          "iopub.status.busy": "2020-09-23T05:16:37.241544Z",
          "iopub.status.idle": "2020-09-23T05:16:38.966529Z",
          "shell.execute_reply": "2020-09-23T05:16:38.965971Z"
        },
        "papermill": {
          "duration": 1.781975,
          "end_time": "2020-09-23T05:16:38.966644",
          "exception": false,
          "start_time": "2020-09-23T05:16:37.184669",
          "status": "completed"
        },
        "tags": [],
        "id": "24U47QraDVOq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LENGTH = 512\n",
        "data['train_question_title'] = get_token_ids(train_df['clean_t_q'], MAX_LENGTH)\n",
        "data['train_answer'] = get_token_ids(train_df['clean_answer'], MAX_LENGTH)\n",
        "data['test_question_title'] = get_token_ids(test_df['clean_t_q'], MAX_LENGTH)\n",
        "data['test_answer'] = get_token_ids(test_df['clean_answer'], MAX_LENGTH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-09-23T05:16:39.043749Z",
          "iopub.status.busy": "2020-09-23T05:16:39.042830Z",
          "iopub.status.idle": "2020-09-23T05:16:39.052713Z",
          "shell.execute_reply": "2020-09-23T05:16:39.052190Z"
        },
        "papermill": {
          "duration": 0.051918,
          "end_time": "2020-09-23T05:16:39.052821",
          "exception": false,
          "start_time": "2020-09-23T05:16:39.000903",
          "status": "completed"
        },
        "tags": [],
        "id": "TNoZpr60DVOt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_fe = train_df[feature_engg_cols].values.astype(np.float32)\n",
        "test_fe = test_df[feature_engg_cols].values.astype(np.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-09-23T05:16:39.132400Z",
          "iopub.status.busy": "2020-09-23T05:16:39.131700Z",
          "iopub.status.idle": "2020-09-23T05:16:39.135164Z",
          "shell.execute_reply": "2020-09-23T05:16:39.135614Z"
        },
        "papermill": {
          "duration": 0.048134,
          "end_time": "2020-09-23T05:16:39.135733",
          "exception": false,
          "start_time": "2020-09-23T05:16:39.087599",
          "status": "completed"
        },
        "tags": [],
        "id": "IcY-d22iDVOx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df['combine_title_question'] = train_df['question_title'] + ' ' + train_df['question_body']\n",
        "test_df['combine_title_question'] = test_df['question_title'] + ' ' + test_df['question_body']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-09-23T05:16:39.222250Z",
          "iopub.status.busy": "2020-09-23T05:16:39.216015Z",
          "iopub.status.idle": "2020-09-23T05:18:52.969318Z",
          "shell.execute_reply": "2020-09-23T05:18:52.968612Z"
        },
        "papermill": {
          "duration": 133.80072,
          "end_time": "2020-09-23T05:18:52.969437",
          "exception": false,
          "start_time": "2020-09-23T05:16:39.168717",
          "status": "completed"
        },
        "tags": [],
        "id": "FzNB0TAXDVO1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder = hub.load('final_models/universal-sentence-encoder-qa_3')\n",
        "\n",
        "data['train_question_title_use'] = []\n",
        "data['train_answer_use'] = []\n",
        "\n",
        "data['test_question_title_use'] = []\n",
        "data['test_answer_use'] = []\n",
        "\n",
        "BATCH_SIZE = 4\n",
        "\n",
        "for i in range(0, train_df.shape[0], BATCH_SIZE):\n",
        "  data['train_question_title_use'] += [encoder.signatures['question_encoder'](\n",
        "      tf.constant(train_df['combine_title_question'].iloc[i:i+BATCH_SIZE].tolist())\n",
        "      )['outputs'].numpy().astype(np.float16)]\n",
        "  data['train_answer_use'] += [encoder.signatures['response_encoder'](\n",
        "      input = tf.constant(train_df['answer'].iloc[i:i+BATCH_SIZE].tolist()), \n",
        "      context = tf.constant(train_df['answer'].iloc[i:i+BATCH_SIZE].tolist())\n",
        "      )['outputs'].numpy().astype(np.float16)]\n",
        "    \n",
        "for i in range(0, test_df.shape[0], BATCH_SIZE):\n",
        "  data['test_question_title_use'] += [encoder.signatures['question_encoder'](\n",
        "      tf.constant(test_df['combine_title_question'].iloc[i:i+BATCH_SIZE].tolist())\n",
        "      )['outputs'].numpy().astype(np.float16)]\n",
        "  data['test_answer_use'] += [encoder.signatures['response_encoder'](\n",
        "      input = tf.constant(test_df['answer'].iloc[i:i+BATCH_SIZE].tolist()), \n",
        "      context = tf.constant(test_df['answer'].iloc[i:i+BATCH_SIZE].tolist())\n",
        "      )['outputs'].numpy().astype(np.float16)]\n",
        "    \n",
        "\n",
        "data['train_question_title_use'] = np.vstack(data['train_question_title_use'])\n",
        "data['train_answer_use'] = np.vstack(data['train_answer_use'])\n",
        "\n",
        "data['test_question_title_use'] = np.vstack(data['test_question_title_use'])\n",
        "data['test_answer_use'] = np.vstack(data['test_answer_use'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-09-23T05:18:53.106827Z",
          "iopub.status.busy": "2020-09-23T05:18:53.096508Z",
          "iopub.status.idle": "2020-09-23T05:18:53.279500Z",
          "shell.execute_reply": "2020-09-23T05:18:53.278865Z"
        },
        "papermill": {
          "duration": 0.273717,
          "end_time": "2020-09-23T05:18:53.279643",
          "exception": false,
          "start_time": "2020-09-23T05:18:53.005926",
          "status": "completed"
        },
        "tags": [],
        "id": "kLlFwlXUDVO5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def is_eng(x):\n",
        "    if ((x == 'english') | (x == 'eli')):\n",
        "        return 1\n",
        "    return 0\n",
        "def question_type(row):\n",
        "    if ((row['is_eng'] == 1) & (row['a_count'] > 85)):\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "train_df['domain'] = train_df.host.apply(lambda s:s.split('.')[0])\n",
        "test_df['domain'] = test_df.host.apply(lambda s:s.split('.')[0])\n",
        "train_df['is_eng'] = train_df.domain.apply(lambda x:is_eng(x))\n",
        "train_df['a_count'] = train_df.answer.apply(lambda x: len(x.split()))\n",
        "train_df['question_type_spelling_modified'] = train_df[['is_eng', 'a_count']].apply(question_type, axis = 1)\n",
        "test_df['is_eng'] = test_df.domain.apply(lambda x:is_eng(x))\n",
        "test_df['a_count'] = test_df.answer.apply(lambda x: len(x.split()))\n",
        "test_df['question_type_spelling_modified'] = test_df[['is_eng', 'a_count']].apply(question_type, axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-09-23T05:18:53.372833Z",
          "iopub.status.busy": "2020-09-23T05:18:53.371314Z",
          "iopub.status.idle": "2020-09-23T05:18:53.373941Z",
          "shell.execute_reply": "2020-09-23T05:18:53.374527Z"
        },
        "papermill": {
          "duration": 0.058986,
          "end_time": "2020-09-23T05:18:53.374646",
          "exception": false,
          "start_time": "2020-09-23T05:18:53.315660",
          "status": "completed"
        },
        "tags": [],
        "id": "UkDtA7dhDVO8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_generator(X, batch_size = 32, training = True):\n",
        "    Y = X[1]\n",
        "    N = X[0][0].shape[0]\n",
        "    if training == True:\n",
        "        indexes = np.arange(N)\n",
        "    else:\n",
        "        indexes = np.arange(N)\n",
        "    def generator():\n",
        "        for i in indexes:\n",
        "            yield {\"input_1\": X[0][0][i], \"input_2\": X[0][1][i],\"input_3\": X[0][2][i], \"input_4\": X[0][3][i], \"input_5\": X[0][4][i]}, Y[i]\n",
        "    return tf.data.Dataset.from_generator(generator, \n",
        "    output_types = ({\"input_1\": tf.int32, \"input_2\": tf.int32,\"input_3\": tf.float16, \"input_4\": tf.float16, \"input_5\": tf.float32}, tf.float32)).repeat().batch(batch_size)\n",
        "\n",
        "def SpearmanCorrCoeff(A, B):\n",
        "  overall_score = 0\n",
        "  for index in range(A.shape[1]):\n",
        "      overall_score += spearmanr(A[:, index], B[:, index]).correlation\n",
        "  return np.round(overall_score/A.shape[1], 3)\n",
        "\n",
        "class PredictCallback(tf.keras.callbacks.Callback):\n",
        "  def __init__(self, data, labels):\n",
        "    self.data = data\n",
        "    self.labels = labels\n",
        "  def on_epoch_end(self, epoch, logs = {}):\n",
        "    predictions = self.model.predict(self.data)\n",
        "    print('\\nValidation Score - ' + str(SpearmanCorrCoeff(self.labels, predictions)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-09-23T05:18:53.450601Z",
          "iopub.status.busy": "2020-09-23T05:18:53.449784Z",
          "iopub.status.idle": "2020-09-23T05:18:53.452812Z",
          "shell.execute_reply": "2020-09-23T05:18:53.452226Z"
        },
        "papermill": {
          "duration": 0.043129,
          "end_time": "2020-09-23T05:18:53.452914",
          "exception": false,
          "start_time": "2020-09-23T05:18:53.409785",
          "status": "completed"
        },
        "tags": [],
        "id": "OyVJSr7ODVO_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def c_lstm(max_length):\n",
        "  i1 = tf.keras.layers.Input(shape = (max_length))\n",
        "  i2 = tf.keras.layers.Input(shape = (max_length))\n",
        "  i3 = tf.keras.layers.Input(shape = (512), dtype = tf.float16)\n",
        "  i4 = tf.keras.layers.Input(shape = (512), dtype = tf.float16)\n",
        "  hand_features = tf.keras.layers.Input(shape = (train_fe.shape[1]), dtype = tf.float32)\n",
        "\n",
        "  e1 = tf.keras.layers.Embedding(input_dim = embedding_matrix.shape[0], output_dim = embedding_matrix.shape[1], weights = [embedding_matrix], trainable = False)(i1)\n",
        "  e2 = tf.keras.layers.Embedding(input_dim = embedding_matrix.shape[0], output_dim = embedding_matrix.shape[1], weights = [embedding_matrix], trainable = False)(i2)\n",
        "  \n",
        "  conv_1 = tf.keras.layers.Conv1D(filters = 300, kernel_size = 1, strides = 1)(e1)\n",
        "  conv_2 = tf.keras.layers.Conv1D(filters = 300, kernel_size = 1, strides = 1)(e2)\n",
        "\n",
        "  sd_i1 = tf.keras.layers.SpatialDropout1D(0.2)(conv_1)\n",
        "  sd_i2 = tf.keras.layers.SpatialDropout1D(0.2)(conv_2)\n",
        "\n",
        "\n",
        "  lstm_q_1 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences = True))(sd_i1)\n",
        "  lstm_q_2 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences = True))(lstm_q_1)\n",
        "    \n",
        "  lstm_a_1 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences = True))(sd_i2)\n",
        "  lstm_a_2 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences = True))(lstm_a_1)\n",
        "\n",
        "  max_pool_1 = tf.keras.layers.GlobalMaxPooling1D()(lstm_q_2)\n",
        "  avg_pool_1 = tf.keras.layers.GlobalAveragePooling1D()(lstm_q_2)\n",
        "  max_pool_2 = tf.keras.layers.GlobalMaxPooling1D()(lstm_a_2)\n",
        "  avg_pool_2 = tf.keras.layers.GlobalAveragePooling1D()(lstm_a_2)\n",
        "\n",
        "  \n",
        "  concat = tf.keras.layers.Concatenate()([max_pool_1, max_pool_2, avg_pool_1, avg_pool_2, i3, i4, hand_features])\n",
        "  \n",
        "  dense = tf.keras.layers.Dense(784, activation = 'relu')(concat)\n",
        "  \n",
        "  drop = tf.keras.layers.Dropout(rate = 0.3)(dense)\n",
        "  \n",
        "  out = tf.keras.layers.Dense(30, activation = 'sigmoid')(drop)\n",
        "\n",
        "  model = tf.keras.Model(inputs = [i1, i2, i3, i4, hand_features], outputs = [out])\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-09-23T05:18:53.530394Z",
          "iopub.status.busy": "2020-09-23T05:18:53.529318Z",
          "iopub.status.idle": "2020-09-23T05:18:53.534872Z",
          "shell.execute_reply": "2020-09-23T05:18:53.534361Z"
        },
        "papermill": {
          "duration": 0.04762,
          "end_time": "2020-09-23T05:18:53.534968",
          "exception": false,
          "start_time": "2020-09-23T05:18:53.487348",
          "status": "completed"
        },
        "tags": [],
        "id": "kuLoh4G-DVPB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_cols = ['question_asker_intent_understanding', 'question_body_critical', 'question_conversational', 'question_expect_short_answer', \n",
        "               'question_fact_seeking', 'question_has_commonly_accepted_answer', 'question_interestingness_others', 'question_interestingness_self', \n",
        "               'question_multi_intent', 'question_not_really_a_question', 'question_opinion_seeking', 'question_type_choice', 'question_type_compare', \n",
        "               'question_type_consequence', 'question_type_definition', 'question_type_entity', 'question_type_instructions', 'question_type_procedure', \n",
        "               'question_type_reason_explanation', 'question_type_spelling', 'question_well_written', 'answer_helpful', 'answer_level_of_information', \n",
        "               'answer_plausible', 'answer_relevance', 'answer_satisfaction', 'answer_type_instructions', 'answer_type_procedure', 'answer_type_reason_explanation', \n",
        "               'answer_well_written']\n",
        "final_outputs = train_df[target_cols].values.astype(np.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-09-23T05:18:53.613428Z",
          "iopub.status.busy": "2020-09-23T05:18:53.612721Z",
          "iopub.status.idle": "2020-09-23T05:18:53.617066Z",
          "shell.execute_reply": "2020-09-23T05:18:53.616419Z"
        },
        "papermill": {
          "duration": 0.045492,
          "end_time": "2020-09-23T05:18:53.617188",
          "exception": false,
          "start_time": "2020-09-23T05:18:53.571696",
          "status": "completed"
        },
        "tags": [],
        "id": "sMnccs70DVPD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if os.path.exists('final_models/c-lstm-save') == False:\n",
        "    gkf = GroupKFold(n_splits = 5).split(X=train_df.url, groups = train_df.url)\n",
        "\n",
        "    for fold, (train_idx, valid_idx) in enumerate(gkf):\n",
        "        if fold != 2:\n",
        "            continue\n",
        "        prev_weights = None\n",
        "        print(f\"-------------------------------------------- Fold - {fold} ----------------------------------------------------\")\n",
        "        train_inputs = ((data['train_question_title'][train_idx], data['train_answer'][train_idx],\n",
        "                        data['train_question_title_use'][train_idx], data['train_answer_use'][train_idx], train_fe[train_idx]), (final_outputs[train_idx]))\n",
        "        valid_inputs = ((data['train_question_title'][valid_idx], data['train_answer'][valid_idx],\n",
        "                        data['train_question_title_use'][valid_idx], data['train_answer_use'][valid_idx], train_fe[valid_idx]), (final_outputs[valid_idx]))\n",
        "        BATCH_SIZE = 28\n",
        "        train_dataset = get_generator(train_inputs)\n",
        "        valid_dataset = tf.data.Dataset.from_tensor_slices(valid_inputs).batch(BATCH_SIZE)\n",
        "\n",
        "        np.random.seed(SEED)\n",
        "        rn.seed(SEED)\n",
        "        tf.random.set_seed(SEED)\n",
        "        model = c_lstm(MAX_LENGTH)\n",
        "        optimizer = tf.keras.optimizers.Nadam(1*1e-3, beta_1=0.7, beta_2=0.777)\n",
        "        model.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "\n",
        "\n",
        "        model.fit(train_dataset, epochs = 4, steps_per_epoch = train_idx.shape[0]//BATCH_SIZE, \n",
        "                    callbacks = [PredictCallback(valid_dataset, final_outputs[valid_idx])])\n",
        "        \n",
        "        break\n",
        "else:\n",
        "    c_lstm_model = tf.keras.models.load_model('final_models/c-lstm-save/c-lstm')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifxAbcWgNz6P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if os.path.exists('final_models/model-save-weights') == False:\n",
        "    gkf = GroupKFold(n_splits = 5).split(X = train_df.url, groups = train_df.url)\n",
        "    for fold, (train_idx, valid_idx) in enumerate(gkf):\n",
        "        if fold != main_fold:\n",
        "            continue\n",
        "        final_outputs = train_df[cols].values.astype(np.float16)\n",
        "        tf.keras.backend.clear_session()\n",
        "        xlnet_train_inputs = (\n",
        "                            data['xlnet_train_a'][tags[0]][train_idx], data['xlnet_train_t_q'][tags[0]][train_idx], data['xlnet_train_a'][tags[1]][train_idx], data['xlnet_train_t_q'][tags[1]][train_idx],\n",
        "                        data['xlnet_train_a'][tags[2]][train_idx], data['xlnet_train_t_q'][tags[2]][train_idx]  \n",
        "                        \n",
        "                        )\n",
        "        xlnet_valid_inputs = (\n",
        "                            data['xlnet_train_a'][tags[0]][valid_idx], data['xlnet_train_t_q'][tags[0]][valid_idx], data['xlnet_train_a'][tags[1]][valid_idx], data['xlnet_train_t_q'][tags[1]][valid_idx],\n",
        "                        data['xlnet_train_a'][tags[2]][valid_idx], data['xlnet_train_t_q'][tags[2]][valid_idx]  \n",
        "                        \n",
        "                        )\n",
        "        \n",
        "        xlnet_model = create_model()\n",
        "        xlnet_model.compile(tf.keras.optimizers.Adam(learning_rate = 2*1e-5), loss = tf.keras.losses.BinaryCrossentropy())\n",
        "        xlnet_model.fit(x = xlnet_train_inputs, y = final_outputs[train_idx], epochs = 3, batch_size = 4, steps_per_epoch = train_idx.shape[0]//4)\n",
        "        tf.keras.backend.clear_session()\n",
        "        print(\"\\n####################################################################################################################\\n\")\n",
        "\n",
        "        break\n",
        "else:\n",
        "    xlnet_model = transformer_model()\n",
        "    xlnet_model.load_weights('final_models/model-save-weights/xlnet')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-09-23T05:18:53.721788Z",
          "iopub.status.busy": "2020-09-23T05:18:53.716667Z",
          "iopub.status.idle": "2020-09-23T05:18:53.725492Z",
          "shell.execute_reply": "2020-09-23T05:18:53.724854Z"
        },
        "papermill": {
          "duration": 0.070174,
          "end_time": "2020-09-23T05:18:53.725605",
          "exception": false,
          "start_time": "2020-09-23T05:18:53.655431",
          "status": "completed"
        },
        "tags": [],
        "id": "ZRQHDv5cDVPH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Optimize:\n",
        "    def __init__(self):\n",
        "        self.clips = [[0, 1] for i in range(30)]\n",
        "        self.ab_ = [(0, 0.15), (0.85, 1)]\n",
        "        self.new_scores, self.scores = (None, None)\n",
        "    def fit(self, labels, preds):\n",
        "        self.scores = [SpearmanCorrCoeff(labels[:, i:i+1], preds[:, i:i+1]) for i in range(30)]\n",
        "        for i in range(30):\n",
        "            self.golden_section_search(labels[:, i:i+1], preds[:, i:i+1], i, 0)\n",
        "            self.golden_section_search(labels[:, i:i+1], preds[:, i:i+1], i, 1)\n",
        "        self.new_scores = [np.nan_to_num(SpearmanCorrCoeff(labels[:, i:i+1], np.clip(preds[:, i:i+1], self.clips[i][0], self.clips[i][1]))) for i in range(30)]\n",
        "        for i in range(30):\n",
        "            if self.scores[i] >= self.new_scores[i]:\n",
        "                self.clips[i] = [0, 1]\n",
        "    def golden_section_search(self, labels, preds, i, idx):\n",
        "        (a, b) = self.ab_[idx]\n",
        "        c = 0.618\n",
        "        x1 = b - c*(b-a)\n",
        "        x2 = (b-a)*c + a\n",
        "        \n",
        "        for epochs in range(20):\n",
        "            self.clips[i][idx] = x1\n",
        "            score_a = -self.score(labels, preds, i)\n",
        "            self.clips[i][idx] = x2\n",
        "            score_b = -self.score(labels, preds, i)\n",
        "            if np.isnan(score_a):\n",
        "                score_a = 0\n",
        "            elif np.isnan(score_b):\n",
        "                score_b = 0\n",
        "            elif score_a <= score_b:\n",
        "                b = x2\n",
        "                x2 = x1\n",
        "                x1 = b - c*(b-a)\n",
        "            else:\n",
        "                a = x1\n",
        "                x1 = x2\n",
        "                x2 = (b-a)*c + a\n",
        "        \n",
        "        self.clips[i][idx] = x1\n",
        "        score_x1 = self.score(labels, preds, i)\n",
        "        self.clips[i][idx] = x2\n",
        "        score_x2 = self.score(labels, preds, i)\n",
        "        if score_x1 > score_x2:\n",
        "            self.clips[i][idx] = x1\n",
        "        else:\n",
        "            self.clips[i][idx] = x2\n",
        "                    \n",
        "            \n",
        "    def score(self, labels, preds, i):\n",
        "        return SpearmanCorrCoeff(labels, np.clip(preds, self.clips[i][0], self.clips[i][1]))\n",
        "    def transform(self, preds):\n",
        "        temp = preds.copy()\n",
        "        for i in range(30):\n",
        "            clipped = np.clip(preds[:, i], self.clips[i][0], self.clips[i][1])\n",
        "            if np.unique(clipped).shape[0] > 1:\n",
        "                temp[:, i][:] = clipped\n",
        "        return temp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-09-23T05:18:53.817939Z",
          "iopub.status.busy": "2020-09-23T05:18:53.817003Z",
          "iopub.status.idle": "2020-09-23T05:18:53.840220Z",
          "shell.execute_reply": "2020-09-23T05:18:53.839621Z"
        },
        "papermill": {
          "duration": 0.076297,
          "end_time": "2020-09-23T05:18:53.840372",
          "exception": false,
          "start_time": "2020-09-23T05:18:53.764075",
          "status": "completed"
        },
        "tags": [],
        "id": "ByFwm1WyDVPJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gkf = GroupKFold(n_splits = 5).split(X=train_df.url, groups = train_df.url)\n",
        "for fold, (train_idx, valid_idx) in enumerate(gkf):\n",
        "  if fold == 2:\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-09-23T05:18:54.013132Z",
          "iopub.status.busy": "2020-09-23T05:18:54.012293Z",
          "iopub.status.idle": "2020-09-23T05:28:48.201368Z",
          "shell.execute_reply": "2020-09-23T05:28:48.199811Z"
        },
        "papermill": {
          "duration": 594.235198,
          "end_time": "2020-09-23T05:28:48.201512",
          "exception": false,
          "start_time": "2020-09-23T05:18:53.966314",
          "status": "completed"
        },
        "tags": [],
        "id": "5pX6hAJtDVPP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_y = final_outputs[train_idx]\n",
        "\n",
        "valid_y = final_outputs[valid_idx]\n",
        "\n",
        "c_lstm_inputs = (data['train_question_title'], data['train_answer'],\n",
        "                   data['train_question_title_use'], data['train_answer_use'], train_fe)\n",
        "c_lstm_predictions = c_lstm_model.predict(c_lstm_inputs)\n",
        "c_lstm_train_predictions = c_lstm_predictions[train_idx]\n",
        "c_lstm_valid_predictions = c_lstm_predictions[valid_idx]\n",
        "\n",
        "xlnet_inputs = (\n",
        "                    data['xlnet_train_a'][tags[0]], data['xlnet_train_t_q'][tags[0]], data['xlnet_train_a'][tags[1]], data['xlnet_train_t_q'][tags[1]],\n",
        "                   data['xlnet_train_a'][tags[2]], data['xlnet_train_t_q'][tags[2]]  \n",
        "                  \n",
        "                 )\n",
        "xlnet_predictions = xlnet_model.predict(xlnet_inputs)\n",
        "xlnet_train_preds = xlnet_predictions[train_idx]\n",
        "xlnet_valid_preds = xlnet_predictions[valid_idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHOex2Eta5a-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "5d53519e-8f3e-4d8f-8d48-4b3653781763"
      },
      "source": [
        "print(f\"Spearman Correlation Coefficient CNN-LSTM : {SpearmanCorrCoeff(c_lstm_valid_predictions, valid_y)}\" )\n",
        "print(f\"Spearman Correlation Coefficient XLNET : {SpearmanCorrCoeff(xlnet_valid_preds, valid_y)}\" )"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Spearman Correlation Coefficient CNN-LSTM : 0.394\n",
            "Spearman Correlation Coefficient XLNET : 0.398\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rz2ylv0RbPNw",
        "colab_type": "text"
      },
      "source": [
        "# Applying Blending and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-09-23T05:28:48.285232Z",
          "iopub.status.busy": "2020-09-23T05:28:48.284605Z",
          "iopub.status.idle": "2020-09-23T05:28:48.298519Z",
          "shell.execute_reply": "2020-09-23T05:28:48.298027Z"
        },
        "papermill": {
          "duration": 0.055809,
          "end_time": "2020-09-23T05:28:48.298617",
          "exception": false,
          "start_time": "2020-09-23T05:28:48.242808",
          "status": "completed"
        },
        "tags": [],
        "id": "ejXFHz99DVPR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_score_preds = 0.5*c_lstm_train_predictions + 0.5*xlnet_train_preds\n",
        "valid_score_preds = 0.5*c_lstm_valid_predictions + 0.5*xlnet_valid_preds\n",
        "train_score_preds[:, 19] = np.multiply(train_df['question_type_spelling_modified'].iloc[train_idx].values, train_score_preds[:, 19])\n",
        "valid_score_preds[:, 19] = np.multiply(train_df['question_type_spelling_modified'].iloc[valid_idx].values, valid_score_preds[:, 19])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-09-23T05:28:48.375243Z",
          "iopub.status.busy": "2020-09-23T05:28:48.374365Z",
          "iopub.status.idle": "2020-09-23T05:28:52.208446Z",
          "shell.execute_reply": "2020-09-23T05:28:52.207696Z"
        },
        "papermill": {
          "duration": 3.874243,
          "end_time": "2020-09-23T05:28:52.208582",
          "exception": false,
          "start_time": "2020-09-23T05:28:48.334339",
          "status": "completed"
        },
        "tags": [],
        "id": "Ws9GBu1sDVPU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt = Optimize()\n",
        "opt.fit(train_y, train_score_preds)\n",
        "post_valid_predictions = opt.transform(valid_score_preds)\n",
        "print(f\"Validation Score Blending : {SpearmanCorrCoeff(valid_y, valid_score_preds)}\")\n",
        "print(f\"Validation Score Blending + Optimizer {SpearmanCorrCoeff(valid_y, post_valid_predictions)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "papermill": {
          "duration": 0.041543,
          "end_time": "2020-09-23T05:29:38.565665",
          "exception": false,
          "start_time": "2020-09-23T05:29:38.524122",
          "status": "completed"
        },
        "tags": [],
        "id": "FeqH6YUUDVPf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from prettytable import PrettyTable\n",
        "    \n",
        "x = PrettyTable()\n",
        "\n",
        "x.field_names = [\"Modeling Strategy\", \"CV Score\"]\n",
        "\n",
        "x.add_row([\"CNN-LSTM\", 0.394])\n",
        "x.add_row([\"XLNET\", 0.398])\n",
        "x.add_row([\"Blending\", 0.424])\n",
        "x.add_row([\"Blending + Optimization\", 0.442])\n",
        "\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekvu2vYqdnfQ",
        "colab_type": "text"
      },
      "source": [
        "# References\n",
        "* https://www.kaggle.com/sakami/google-quest-single-lstm?scriptVersionId=28487242 - The CNN-LSTM takes some inspiration from this kernel\n",
        "* https://www.kaggle.com/christofhenkel/how-to-preprocessing-when-using-embeddings - Preprocessing of text data is inspired from this kernel\n",
        "* https://huggingface.co/ - Documentation for Huggingface Library\n",
        "* https://www.kaggle.com/c/google-quest-challenge/discussion/130041 - Used the hack for question_type_spelling\n"
      ]
    }
  ]
}